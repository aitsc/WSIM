import pickle
import copy
import time
import datetime
import re
import math
from numpy import float128 as double
from collections import Counter
import sys
import os
from scipy.spatial import distance
import random
from pprint import pprint


def insertToModifyFileName(text, filePath, head=False):
    path, extension = os.path.splitext(filePath)
    fatherPath, name = os.path.split(path)
    if head:
        return fatherPath + os.sep + text + name + extension
    else:
        return fatherPath + os.sep + name + text + extension


class 处理11:
    @staticmethod
    def 计算正确率(计算排名_作者号向量, 标准排名_作者号向量, N):
        if N > len(计算排名_作者号向量):
            N = len(计算排名_作者号向量)
        正确率 = len(set(计算排名_作者号向量[:N]) & set(标准排名_作者号向量)) / N
        return 正确率

    @staticmethod
    def 计算召回率(计算排名_作者号向量, 标准排名_作者号向量, N):
        if N > len(计算排名_作者号向量):
            N = len(计算排名_作者号向量)
        召回率 = len(set(计算排名_作者号向量[:N]) & set(标准排名_作者号向量)) / len(标准排名_作者号向量)
        return 召回率

    @staticmethod
    def 计算P_N指标(计算排名_作者号向量, 标准排名_作者号向量, N):
        if N > len(计算排名_作者号向量):
            N = len(计算排名_作者号向量)
        P_N指标 = 0
        for i in range(N):
            if 计算排名_作者号向量[i] in 标准排名_作者号向量:
                P_N指标 += 1
        P_N指标 /= N
        return P_N指标

    @staticmethod
    def 计算MAP指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N, 不考虑顺序=True):
        if N > len(文档索引_计算排名_作者号矩阵[0]):
            N = len(文档索引_计算排名_作者号矩阵[0])
        MAP指标 = 0
        for 第n个文档 in range(len(文档索引_计算排名_作者号矩阵)):
            MAP指标_一个文档 = 0
            计算排名_作者号向量 = 文档索引_计算排名_作者号矩阵[第n个文档]
            标准排名_作者号向量 = 文档索引_标准排名_作者号矩阵[第n个文档]
            for i in range(N):
                计算排名 = i + 1
                if 计算排名_作者号向量[i] in 标准排名_作者号向量:
                    标准排名 = 标准排名_作者号向量.index(计算排名_作者号向量[i]) + 1
                    if 不考虑顺序:
                        标准排名 = 计算排名
                else:
                    标准排名 = len(标准排名_作者号向量) + 1
                if 标准排名 > 计算排名:
                    MAP指标_一个文档 += 计算排名 / 标准排名
                else:
                    MAP指标_一个文档 += 标准排名 / 计算排名
            MAP指标 += MAP指标_一个文档 / N
        MAP指标 /= len(文档索引_计算排名_作者号矩阵)
        return MAP指标

    @staticmethod
    def 计算NDCG指标(计算排名_作者号向量, 标准排名_作者号向量, N, 不考虑顺序=True):
        if N > len(计算排名_作者号向量):
            N = len(计算排名_作者号向量)
        计算排名_作者号_标准得分表 = []
        for 计算排名 in range(len(计算排名_作者号向量)):
            作者号 = 计算排名_作者号向量[计算排名]
            if 作者号 in 标准排名_作者号向量:
                标准排名 = 标准排名_作者号向量.index(作者号) + 1
                if 不考虑顺序:
                    标准排名 = 1
            else:
                标准排名 = len(标准排名_作者号向量) + 1
            计算排名_作者号_标准得分表.append([作者号, 1 / 标准排名])
        完美排序_作者号_标准得分表 = sorted(计算排名_作者号_标准得分表, key=lambda t: t[1], reverse=True)
        DCG_N = 计算排名_作者号_标准得分表[0][1]
        IDCG_N = 完美排序_作者号_标准得分表[0][1]
        for i in range(1, N):
            DCG_N += 计算排名_作者号_标准得分表[i][1] / math.log2(i + 1)
            IDCG_N += 完美排序_作者号_标准得分表[i][1] / math.log2(i + 1)
        return DCG_N / IDCG_N

    @staticmethod
    def 计算多文档P_N指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N):
        文档索引_PN指标向量 = []
        for i in range(len(文档索引_计算排名_作者号矩阵)):
            文档索引_PN指标向量.append(处理11.计算P_N指标(文档索引_计算排名_作者号矩阵[i],
                                            文档索引_标准排名_作者号矩阵[i], N))
        return 文档索引_PN指标向量

    @staticmethod
    def 计算多文档NDCG指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N):
        文档索引_NDCG指标向量 = []
        for i in range(len(文档索引_计算排名_作者号矩阵)):
            文档索引_NDCG指标向量.append(处理11.计算NDCG指标(文档索引_计算排名_作者号矩阵[i],
                                               文档索引_标准排名_作者号矩阵[i], N))
        return 文档索引_NDCG指标向量

    @staticmethod
    def 计算多文档Fbeta指标_micro(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N, beta=1):
        if N > len(文档索引_计算排名_作者号矩阵[0]):
            N = len(文档索引_计算排名_作者号矩阵[0])
        总计算正确数 = 0
        总标准正确数 = 0
        for 第n文档 in range(len(文档索引_计算排名_作者号矩阵)):
            计算排名_作者号向量 = 文档索引_计算排名_作者号矩阵[第n文档]
            标准排名_作者号向量 = 文档索引_标准排名_作者号矩阵[第n文档]
            总标准正确数 += len(标准排名_作者号向量)
            总计算正确数 += len(set(计算排名_作者号向量[:N]) & set(标准排名_作者号向量))
        准确率 = 总计算正确数 / (len(文档索引_计算排名_作者号矩阵) * N)
        召回率 = 总计算正确数 / 总标准正确数
        if 准确率 == 0 and 召回率 == 0:
            return 0
        Fbeta指标 = (1 + beta ** 2) * 准确率 * 召回率 / (beta ** 2 * 准确率 + 召回率)
        return Fbeta指标

    @staticmethod
    def 计算多文档Fbeta指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N, beta=1):
        准确率 = 处理11.计算多文档正确率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
        召回率 = 处理11.计算多文档召回率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
        if 准确率 == 0 and 召回率 == 0:
            return 0
        Fbeta指标 = (1 + beta ** 2) * 准确率 * 召回率 / (beta ** 2 * 准确率 + 召回率)
        return Fbeta指标

    @staticmethod
    def 计算多文档正确率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N):
        多文档正确率 = 0
        for 第n文档 in range(len(文档索引_计算排名_作者号矩阵)):
            计算排名_作者号向量 = 文档索引_计算排名_作者号矩阵[第n文档]
            标准排名_作者号向量 = 文档索引_标准排名_作者号矩阵[第n文档]
            多文档正确率 += 处理11.计算正确率(计算排名_作者号向量, 标准排名_作者号向量, N)
        多文档正确率 /= len(文档索引_计算排名_作者号矩阵)
        return 多文档正确率

    @staticmethod
    def 计算多文档召回率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N):
        多文档召回率 = 0
        for 第n文档 in range(len(文档索引_计算排名_作者号矩阵)):
            计算排名_作者号向量 = 文档索引_计算排名_作者号矩阵[第n文档]
            标准排名_作者号向量 = 文档索引_标准排名_作者号矩阵[第n文档]
            多文档召回率 += 处理11.计算召回率(计算排名_作者号向量, 标准排名_作者号向量, N)
        多文档召回率 /= len(文档索引_计算排名_作者号矩阵)
        return 多文档召回率

    @staticmethod
    def 计算多文档反Fbeta指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, beta=1):
        N = 0
        作者号_计算排名_文档索引广义表字典 = {}
        for 文档索引 in range(len(文档索引_计算排名_作者号矩阵)):
            for 作者号 in 文档索引_计算排名_作者号矩阵[文档索引]:
                if 作者号 in 作者号_计算排名_文档索引广义表字典:
                    作者号_计算排名_文档索引广义表字典[作者号].append(文档索引)
                else:
                    作者号_计算排名_文档索引广义表字典.update([(作者号, [文档索引])])
        作者号_标准排名_文档索引广义表字典 = {}
        for 文档索引 in range(len(文档索引_标准排名_作者号矩阵)):
            for 作者号 in 文档索引_标准排名_作者号矩阵[文档索引]:
                if 作者号 in 作者号_标准排名_文档索引广义表字典:
                    作者号_标准排名_文档索引广义表字典[作者号].append(文档索引)
                else:
                    作者号_标准排名_文档索引广义表字典.update([(作者号, [文档索引])])
                if len(作者号_标准排名_文档索引广义表字典[作者号]) > N:
                    N = len(作者号_标准排名_文档索引广义表字典[作者号])
        总计算正确数 = 0
        总标准正确数 = 0
        for 作者号 in 作者号_标准排名_文档索引广义表字典.keys():
            标准排名_文档索引向量 = 作者号_标准排名_文档索引广义表字典[作者号]
            总标准正确数 += len(标准排名_文档索引向量)
            if 作者号 not in 作者号_计算排名_文档索引广义表字典:
                continue
            计算排名_文档索引向量 = 作者号_计算排名_文档索引广义表字典[作者号]
            总计算正确数 += len(set(计算排名_文档索引向量[:N]) & set(标准排名_文档索引向量))
        准确率 = 总计算正确数 / (len(作者号_标准排名_文档索引广义表字典) * N)
        召回率 = 总计算正确数 / 总标准正确数
        if 准确率 == 0 and 召回率 == 0:
            return 0
        反Fbeta指标 = (1 + beta ** 2) * 准确率 * 召回率 / (beta ** 2 * 准确率 + 召回率)
        return 反Fbeta指标

    @staticmethod
    def MAP_相关文档数为N(预测向量组l, 标签向量组l, N):
        AP = []
        相关文档数 = N
        for i in range(len(预测向量组l)):
            预测向量l = 预测向量组l[i][:N]
            标签向量s = set(标签向量组l[i])
            准确个数 = 0
            ap = 0
            for j in range(相关文档数):
                if 预测向量l[j] in 标签向量s:
                    准确个数 += 1
                    ap += 准确个数 / (j + 1)
            AP.append(ap / 相关文档数)
        return sum(AP) / len(AP)

    @staticmethod
    def NDCG_无序(预测向量组l, 标签向量组l, N):
        ndcg = 0
        idcg = sum(1 / math.log2(i + 2) for i in range(N))
        for i in range(len(预测向量组l)):
            预测向量l = 预测向量组l[i][:N]
            标签向量s = set(标签向量组l[i])
            for j in range(len(预测向量l)):
                if 预测向量l[j] in 标签向量s:
                    ndcg += 1 / math.log2(j + 2)
        return ndcg / idcg / len(预测向量组l)

    @staticmethod
    def Bpref_相关文档数为N(预测向量组l, 标签向量组l, N):
        bpref = 0
        相关文档数 = N
        for i in range(len(预测向量组l)):
            预测向量l = 预测向量组l[i][:N]
            标签向量s = set(标签向量组l[i])
            不准确个数 = 0
            for j in range(相关文档数):
                if 预测向量l[j] not in 标签向量s:
                    不准确个数 += 1
                bpref += (1 - 不准确个数 / 相关文档数)
        return bpref / 相关文档数 / len(预测向量组l)


class 迭代周围得分方式:
    @staticmethod
    def 衰减求和_分段_舍弃最后归一化(求和列表, 衰减系数=0.25, 每段个数=1):
        和 = 0
        求和列表 = sorted(求和列表, reverse=True)

        总段数 = int(len(求和列表) / 每段个数)
        if len(求和列表) % 每段个数 != 0:
            总段数 += 1
            最后一段个数 = len(求和列表) % 每段个数
        else:
            最后一段个数 = 每段个数
        衰减程度 = 衰减系数
        衰减总和 = 1 - (1 - 衰减系数) ** 总段数

        for i in range(总段数 - 1):
            一段得分 = sum(求和列表[i * 每段个数:(i + 1) * 每段个数]) / 每段个数
            和 += 一段得分 * 衰减程度 / 衰减总和
            衰减程度 *= (1 - 衰减系数)
        一段得分 = sum(求和列表[(总段数 - 1) * 每段个数:]) / 最后一段个数
        和 += 一段得分 * 衰减程度 / 衰减总和
        return 和

    @staticmethod
    def 衰减求和_分段(求和列表, 衰减系数=0.25, 每段个数=1):
        和 = 0
        求和列表 = sorted(求和列表, reverse=True)

        总段数 = int(len(求和列表) / 每段个数)
        if len(求和列表) % 每段个数 != 0:
            总段数 += 1
            最后一段个数 = len(求和列表) % 每段个数
        else:
            最后一段个数 = 每段个数
        衰减程度 = 衰减系数

        for i in range(总段数 - 1):
            一段得分 = sum(求和列表[i * 每段个数:(i + 1) * 每段个数]) / 每段个数
            和 += 一段得分 * 衰减程度
            衰减程度 *= (1 - 衰减系数)
        一段得分 = sum(求和列表[(总段数 - 1) * 每段个数:]) / 最后一段个数
        和 += 一段得分 * 衰减程度 / 衰减系数
        return 和

    @staticmethod
    def 衰减求和(求和列表, 衰减系数=0.25):
        return 迭代周围得分方式.衰减求和_分段(求和列表, 衰减系数=衰减系数, 每段个数=1)

    @staticmethod
    def 衰减求和_舍弃最后(求和列表, 衰减系数=0.25, 是否排序=True):
        # 会越迭代越小
        和 = 0
        衰减程度 = 衰减系数
        if 是否排序:
            求和列表 = sorted(求和列表, reverse=True)
        for 一个数 in 求和列表:
            和 += 一个数 * 衰减程度
            衰减程度 *= (1 - 衰减系数)
        return 和

    @staticmethod
    def 平均求和(求和列表):
        和 = 0
        for 一个数 in 求和列表:
            和 += 一个数
        和 = 和 / len(求和列表)
        return 和


def 取字典第一个(字典):
    for 键, 值 in 字典.items():
        return 键, 值


def 输出全局参数(locals字典, 参数前缀, 参数后缀=None, 参数名字符上限=100, 参数内容字符上限=100, 直接输出=True):
    全局参数 = {}
    if 参数前缀 == None or len(参数前缀) == 0:
        return 全局参数
    for 参数, 内容 in locals字典.items():
        if 参数[:len(参数前缀)] != 参数前缀:
            continue
        else:
            参数 = 参数[len(参数前缀):]
        if 参数后缀 != None and len(参数后缀) > 0 and 参数[-len(参数后缀):] != 参数后缀:
            continue
        elif 参数后缀 != None and len(参数后缀) > 0 and 参数[-len(参数后缀):] == 参数后缀:
            参数 = 参数[:-len(参数后缀)]
        if len(参数) > 参数名字符上限:
            continue
        内容x = str(内容)
        if 内容x[0] == '<' and 内容x[-1] == '>' and not isinstance(内容, str):
            try:
                if 内容x[1] == 'f' or 内容x[1] == 'c':
                    内容x = 内容.__name__
            except:
                continue
        if len(内容x) > 参数内容字符上限:
            continue
        全局参数[参数] = 内容x
    if 直接输出 and len(全局参数) > 0:
        print('参数: ', end='')
        for 参数, 内容 in 全局参数.items():
            print('%s=%s; ' % (参数, 内容), end='')
        print()
    return 全局参数


class 覆盖或距离计算():
    @staticmethod
    def JS相似度计算(分布1, 分布2):
        if len(分布1) != len(分布2):
            return None
        JS散度 = distance.jensenshannon(分布1, 分布2) ** 2
        return - JS散度

    @staticmethod
    def 覆盖度计算(分布1, 分布2, 第二分布为被覆盖对象=True):
        if len(分布1) != len(分布2):
            return None
        if not 第二分布为被覆盖对象:
            分布1, 分布2 = 分布2, 分布1
        覆盖度 = 0
        总覆盖值 = 0
        for i in range(len(分布1)):
            总覆盖值 += 分布2[i]
            if 分布1[i] > 分布2[i]:
                覆盖度 += 分布2[i]
            else:
                覆盖度 += 分布1[i]
        if 总覆盖值 == 0:
            return 0
        覆盖度 /= 总覆盖值
        return 覆盖度

    @staticmethod
    def 余弦相似度计算(分布1, 分布2):
        if len(分布1) != len(分布2):
            return None
        分布1_模 = 0
        分布2_模 = 0
        分布1_分布2 = 0
        for i in range(len(分布1)):
            分布1_模 += 分布1[i] ** 2
            分布2_模 += 分布2[i] ** 2
            分布1_分布2 += 分布1[i] * 分布2[i]
        余弦相似度 = 分布1_分布2 / (分布1_模 * 分布2_模) ** 0.5  # 2018年09月10日 修正错误
        return 余弦相似度

    @staticmethod
    def 欧式相似度计算(分布1, 分布2):
        if len(分布1) != len(分布2):
            return None
        分布1_分布2 = 0
        for i in range(len(分布1)):
            分布1_分布2 += (分布1[i] - 分布2[i]) ** 2
        欧式距离 = 分布1_分布2 ** 0.5
        return - 欧式距离

    @staticmethod
    def 文档生成概率计算(文档主题分布向量l, 主题词分布矩阵l, 文本词号向量l, 同步扩大系数=1):
        文档生成概率 = double(1)
        for nw in 文本词号向量l:
            一个词的生成概率 = 0
            for nt in range(len(文档主题分布向量l)):
                主题分布概率 = 文档主题分布向量l[nt]
                一个词的生成概率 += 主题词分布矩阵l[nt][nw] * 主题分布概率 * 同步扩大系数 * 同步扩大系数
            文档生成概率 *= 一个词的生成概率
        return 文档生成概率

    @staticmethod
    def NDCG计算(分布1, 分布2, 排名值函数=lambda x: 1 / (x + 1) ** 0.5, 以分布2为标准=True, 使用实际分布得分=False):  # x从0开始
        if len(分布1) != len(分布2):
            return None
        if not 以分布2为标准:
            分布1, 分布2 = 分布2, 分布1
        序号_分布2表l = [[i, 分布2[i]] for i in range(len(分布2))]
        序号_分布2表l_排序 = sorted(序号_分布2表l, key=lambda t: t[1], reverse=True)
        序号_分布2排名表d = {序号_分布2表l_排序[i][0]: i for i in range(len(序号_分布2表l_排序))}
        序号_分布1表l = [[i, 分布1[i]] for i in range(len(分布1))]
        序号_分布1表l_排序 = sorted(序号_分布1表l, key=lambda t: t[1], reverse=True)
        分布1排名序号向量l = [序号_分布1表l_排序[i][0] for i in range(len(序号_分布1表l_排序))]
        if not 使用实际分布得分:
            DCG = 排名值函数(序号_分布2排名表d[分布1排名序号向量l[0]])
            for i in range(1, len(分布1排名序号向量l)):
                DCG += 排名值函数(序号_分布2排名表d[分布1排名序号向量l[i]]) / math.log2(i + 1)
            IDCG = 排名值函数(0)
            for i in range(1, len(分布2)):
                IDCG += 排名值函数(i) / math.log2(i + 1)
            NDCG = DCG / IDCG
            最差DCG = 排名值函数(len(分布2) - 1)
            for i in range(1, len(分布2)):
                最差DCG += 排名值函数(len(分布2) - i - 1) / math.log2(i + 1)
        else:
            DCG = 分布1[分布1排名序号向量l[0]] if 序号_分布2表l_排序[0][1] > 分布1[分布1排名序号向量l[0]] else 序号_分布2表l_排序[0][1]
            for i in range(1, len(分布1排名序号向量l)):
                DCG += (分布1[分布1排名序号向量l[i]] if 序号_分布2表l_排序[i][1] > 分布1[分布1排名序号向量l[i]] else 序号_分布2表l_排序[i][1]) \
                       / math.log2(i + 1)
            IDCG = 序号_分布2表l_排序[0][1]
            for i in range(1, len(分布2)):
                IDCG += 序号_分布2表l_排序[i][1] / math.log2(i + 1)
            NDCG = DCG / IDCG
            最差DCG = 1 / math.log2(len(分布2))
        return (NDCG - 最差DCG / IDCG) / (1 - 最差DCG / IDCG)

    @staticmethod
    def 稀疏向量余弦相似度计算(稀疏向量1d, 稀疏向量2d):
        重合维度 = []
        xy_sum = 0
        x_2_sum = 0
        y_2_sum = 0
        for 维度, 值 in 稀疏向量1d.items():
            x_2_sum += 值 ** 2
            if 维度 in 稀疏向量2d:
                重合维度.append(维度)
        for 一个重合维度 in 重合维度:
            xy_sum += 稀疏向量1d[一个重合维度] * 稀疏向量2d[一个重合维度]
        for 值 in 稀疏向量2d.values():
            y_2_sum += 值 ** 2
        余弦距离 = xy_sum / (x_2_sum * y_2_sum) ** 0.5 if x_2_sum * y_2_sum != 0 else 0
        return 余弦距离

    @staticmethod
    def 逆序数COS相似度(比较分布, 被比较分布):
        联合分布 = [(比较分布[i], 被比较分布[i]) for i in range(len(比较分布))]
        联合分布 = sorted(联合分布, key=lambda t: t[0], reverse=True)
        联合分布_排名 = []
        for i in range(len(联合分布)):
            联合分布_排名.append([i, 联合分布[i]])
        联合分布_排名2 = sorted(联合分布_排名, key=lambda t: t[1][1], reverse=True)
        距离 = 0
        计数 = 0
        for 排名, _ in 联合分布_排名2:
            距离 += (len(联合分布_排名2) - 计数) / (排名 + 1)
            计数 += 1
        余弦相似度 = 覆盖或距离计算.余弦相似度计算(比较分布, 被比较分布)
        return 距离 + 余弦相似度 / 10000


class 测试论文:
    @staticmethod
    def 获取引用论文_文本_选择专家_年份表d(引用论文_文本_选择专家_年份表d地址):
        with open(引用论文_文本_选择专家_年份表d地址, 'rb') as r:
            引用论文_文本_选择专家_年份表d = pickle.load(r)
        return 引用论文_文本_选择专家_年份表d

    @staticmethod
    def 获取词_词号_词次数表d(词号_词次数_词表地址):
        词_词号_词次数表d = {}
        with open(词号_词次数_词表地址, 'r', encoding='utf-8') as r:
            for line in r:
                line = line.strip().split('\t')
                if len(line) < 3:
                    continue
                词_词号_词次数表d[line[2]] = [int(line[0]), int(line[1])]
        return 词_词号_词次数表d

    @staticmethod
    def 获得主题_词分布矩阵l(主题_词分布地址, 文档_主题_次数矩阵地址):
        主题_词分布矩阵l = []
        with open(主题_词分布地址, 'r', encoding='utf-8') as r:
            for line in r:
                line = line.strip().split('\t')
                if len(line) < 2:
                    continue
                主题_词分布矩阵l.append([])
                for i in line:
                    try:
                        主题_词分布矩阵l[-1].append(float(i))
                    except:
                        print(i)
                        print(line)
                        raise
        主题_次数向量 = [0] * len(主题_词分布矩阵l)
        with open(文档_主题_次数矩阵地址, 'r', encoding='utf-8') as r:
            for line in r:
                if len(line.strip()) == 0:
                    continue
                line = line.strip().split('\t')
                for i in range(len(主题_次数向量)):
                    主题_次数向量[i] += int(line[i])
        主题总次数 = sum(主题_次数向量)

        词_主题分布矩阵l = [[0] * len(主题_词分布矩阵l) for i in range(len(主题_词分布矩阵l[0]))]
        词_主题总分布向量l = [0] * len(主题_词分布矩阵l[0])
        for i in range(len(主题_词分布矩阵l)):
            for j in range(len(主题_词分布矩阵l[i])):
                词概率 = 主题_词分布矩阵l[i][j]
                词_主题总分布向量l[j] += 词概率
                词_主题分布矩阵l[j][i] = 词概率
        for nw in range(len(词_主题分布矩阵l)):
            for nt in range(len(词_主题分布矩阵l[nw])):
                词_主题分布矩阵l[nw][nt] /= 词_主题总分布向量l[nw]
        return 主题_词分布矩阵l, 词_主题分布矩阵l

    @staticmethod
    def 计算文本主题次数向量l(文本, 词_词号_词次数表d, 词_主题分布矩阵l):
        主题次数向量l = [0 for i in range(len(词_主题分布矩阵l[0]))]
        文本词向量l = re.split(r'[\r\n\t　 ,\?/;:\(\)<>"\[\]]+', 文本)
        文本词向量l = [i.strip('.-').lower() for i in 文本词向量l]
        文本词号向量l = []
        for 词 in 文本词向量l:
            if 词 in 词_词号_词次数表d:
                文本词号向量l.append(词_词号_词次数表d[词][0])
        for 文本词号 in 文本词号向量l:
            for nt in range(len(词_主题分布矩阵l[0])):
                主题次数向量l[nt] += 词_主题分布矩阵l[文本词号][nt]

        文本词号_出现次数表d = dict(Counter(文本词号向量l))
        标准主题分布向量l = [0 for i in range(len(词_主题分布矩阵l[0]))]
        for 文本词号 in 文本词号向量l:
            for nt in range(len(词_主题分布矩阵l[0])):
                标准主题分布向量l[nt] += 词_主题分布矩阵l[文本词号][nt] * 文本词号_出现次数表d[文本词号] / len(文本词号向量l)

        return 主题次数向量l, 文本词号向量l, 标准主题分布向量l

    @staticmethod
    def 计算主题分布(主题次数向量l, alpha):
        主题分布向量l = []
        主题总次数 = 0
        for i in 主题次数向量l:
            主题总次数 += i
        for i in 主题次数向量l:
            主题分布向量l.append((i + alpha) / (主题总次数 + len(主题次数向量l) * alpha))
        return 主题分布向量l

    def __init__(self, 引用论文_文本_选择专家_年份表d地址, 词号_词次数_词表地址, 主题_词分布地址, alpha, 文档_主题_次数矩阵地址,
                 选择特定稿件编号=[], 选择稿件数量=0):
        引用论文_时间_主题次数向量_答案专家_文本词号表l = []
        引用论文_主题分布向量表d = {}
        引用论文_文本_选择专家_年份表d = self.获取引用论文_文本_选择专家_年份表d(引用论文_文本_选择专家_年份表d地址)
        词_词号_词次数表d = self.获取词_词号_词次数表d(词号_词次数_词表地址)
        主题_词分布矩阵l, 词_主题分布矩阵l = self.获得主题_词分布矩阵l(主题_词分布地址, 文档_主题_次数矩阵地址)
        特定稿件s = self._筛选特定稿件(选择特定稿件编号, 选择稿件数量, 引用论文_文本_选择专家_年份表d)
        for 论文编号, 文本_选择专家_年份 in 引用论文_文本_选择专家_年份表d.items():
            if 论文编号 not in 特定稿件s:
                continue
            文本 = 文本_选择专家_年份[0]
            专家编号向量l = [i for i in 文本_选择专家_年份[1].keys()]
            年份 = 文本_选择专家_年份[2]
            主题次数向量l, 文本词号向量l, 标准主题分布向量l = self.计算文本主题次数向量l(文本, 词_词号_词次数表d, 词_主题分布矩阵l)
            引用论文_主题分布向量表d[论文编号] = 标准主题分布向量l
            引用论文_时间_主题次数向量_答案专家_文本词号表l.append([论文编号, 年份, 主题次数向量l, 专家编号向量l, 文本词号向量l])

        print('加载了%d篇稿件...' % len(引用论文_时间_主题次数向量_答案专家_文本词号表l))

        self.引用论文_时间_主题次数向量_答案专家_文本词号表l = 引用论文_时间_主题次数向量_答案专家_文本词号表l
        self.主题_词分布矩阵l = 主题_词分布矩阵l
        self.论文遍历进度 = 0
        self.alpha = alpha
        self.引用论文_主题分布向量表d = 引用论文_主题分布向量表d

    def _筛选特定稿件(self, 选择特定稿件编号, 选择稿件数量, 引用论文_文本_选择专家_年份表d):
        特定稿件s = set()
        if 选择特定稿件编号 != None and len(选择特定稿件编号) > 0:
            for 稿件编号 in 选择特定稿件编号:
                if 稿件编号 in 引用论文_文本_选择专家_年份表d:
                    特定稿件s.add(稿件编号)
            if len(特定稿件s) > 0:
                特定稿件s = frozenset(特定稿件s)
                return 特定稿件s
        if 选择稿件数量 == None or 选择稿件数量 <= 0:
            选择稿件数量 = len(引用论文_文本_选择专家_年份表d)
        for 稿件编号 in 引用论文_文本_选择专家_年份表d.keys():
            if len(特定稿件s) < 选择稿件数量:
                特定稿件s.add(稿件编号)
            else:
                break
        特定稿件s = frozenset(特定稿件s)
        return 特定稿件s

    def 获得稿件的主题分布向量l(self, 主题次数向量l):
        if isinstance(主题次数向量l, list):
            return self.计算主题分布(主题次数向量l, self.alpha)
        else:
            return self.引用论文_主题分布向量表d[主题次数向量l]

    def 遍历测试论文(self):
        if self.论文遍历进度 >= len(self.引用论文_时间_主题次数向量_答案专家_文本词号表l):
            return None
        self.论文遍历进度 += 1
        return self.引用论文_时间_主题次数向量_答案专家_文本词号表l[self.论文遍历进度 - 1]

    def 重置遍历标记(self):
        self.论文遍历进度 = 0

    def 测试论文数目(self):
        return len(self.引用论文_时间_主题次数向量_答案专家_文本词号表l)

    def 词号向量过滤扩充法(self, 主题次数向量l, 词数阈值=2, 使用词扩充复制=90):
        pass


class 专家:
    def _衰变函数(self, 衰变后时间, 衰变前时间, 半衰期):
        # return 衰变前时间*((1/2)**((衰变后时间-衰变前时间)/半衰期))
        # return 1-0.56*(衰变后时间-衰变前时间)**0.06
        # return (1/(衰变后时间-衰变前时间)) if 衰变后时间-衰变前时间>0 else 1
        return (0.7 ** (衰变后时间 - 衰变前时间)) if 衰变后时间 - 衰变前时间 > 0 else 1

    def __init__(self, 作者号_论文号广义表地址, 专家_主题_时间8出现次数张量d地址, 作者_主题分布地址, 专家_主题_时间8分布张量d地址,
                 文档编号_文档名表地址, 作者号_词_词数广义表地址, 初始总LM值=1.0):
        作者号_论文号字典 = {}
        with open(作者号_论文号广义表地址, 'r', encoding='utf-8') as 读取:
            for 一行 in 读取:
                一行 = 一行.strip().split('\t')
                if len(一行) < 2:
                    continue
                作者号_论文号字典.update([(一行[0], 一行[1:])])
        with open(专家_主题_时间8出现次数张量d地址, 'rb') as r:
            专家_主题_时间8出现次数张量d = pickle.load(r)
        专家_主题_出现次数矩阵d = {}
        for 专家编号, 专家主题_时间8出现次数矩阵l in 专家_主题_时间8出现次数张量d.items():
            专家_主题_出现次数矩阵d[专家编号] = [0] * len(专家主题_时间8出现次数矩阵l)
            for i in range(len(专家主题_时间8出现次数矩阵l)):
                时间8出现次数 = 专家主题_时间8出现次数矩阵l[i]
                主题出现次数 = 0
                for 出现次数 in 时间8出现次数.values():
                    主题出现次数 += 出现次数
                专家_主题_出现次数矩阵d[专家编号][i] = 主题出现次数
        作者_主题分布矩阵l = []
        with open(作者_主题分布地址, encoding='utf-8') as 读取:
            for 一行 in 读取:
                一行 = 一行.strip().split('\t')
                作者_主题分布矩阵l.append([float(i) for i in 一行])
        with open(专家_主题_时间8分布张量d地址, 'rb') as r:
            专家_主题_时间8分布张量d = pickle.load(r)
        作者编号_作者序号表d = {}
        with open(文档编号_文档名表地址, 'r', encoding='utf-8') as r:
            for line in r:
                line = line.strip().split('\t')
                if len(line) < 2:
                    continue
                作者编号_作者序号表d[line[1]] = int(line[0])
        作者编号_词号8tfidf表d, 词号_idf表d, 作者编号_词号8出现次数表d = self.获得作者稀疏tfidf向量(作者号_词_词数广义表地址)
        词号_词次数表, 作者编号_词数表, 平均专家文本长度, 所有作者词总数 = self.获得LM计算所需资源(作者编号_词号8出现次数表d)

        self.重置遍历作者标记()
        self.作者向量l = [i for i in 作者号_论文号字典.keys()]
        self.专家_主题_出现次数矩阵d = 专家_主题_出现次数矩阵d
        self.作者_主题分布矩阵l = 作者_主题分布矩阵l
        self.作者编号_作者序号表d = 作者编号_作者序号表d
        self.作者号_论文号字典 = 作者号_论文号字典
        self.专家_主题_时间8出现次数张量d = 专家_主题_时间8出现次数张量d
        self.专家_主题_时间8分布张量d = 专家_主题_时间8分布张量d
        self.作者编号_词号8tfidf表d = 作者编号_词号8tfidf表d
        self.词号_idf表d = 词号_idf表d
        self.平均专家论文数 = sum([len(i) for i in 作者号_论文号字典.values()]) / len(作者号_论文号字典)
        self.作者编号_词号8出现次数表d = 作者编号_词号8出现次数表d
        self.词号_词次数表 = 词号_词次数表
        self.作者编号_词数表 = 作者编号_词数表
        self.平均专家文本长度 = 平均专家文本长度
        self.所有作者词总数 = 所有作者词总数
        self.初始总LM值 = 初始总LM值
        self.去重复 = True

    def 改变LM计算时是否去除重复词(self, 去重复=True):
        self.去重复 = 去重复

    def 获得LM计算所需资源(self, 作者编号_词号8出现次数表d):
        词号_词次数表 = {}  # {词号:词次数,..}
        作者编号_词数表 = {}  # {作者编号:词数,..}
        平均专家文本长度 = 0
        所有作者词总数 = 0
        for 作者编号, 词号8出现次数 in 作者编号_词号8出现次数表d.items():
            词总数 = 0
            for 词号, 出现次数 in 词号8出现次数.items():
                词总数 += 出现次数
                if 词号 in 词号_词次数表:
                    词号_词次数表[词号] += 出现次数
                else:
                    词号_词次数表[词号] = 出现次数
            作者编号_词数表[作者编号] = 词总数
            所有作者词总数 += 词总数
        平均专家文本长度 = 所有作者词总数 / len(作者编号_词号8出现次数表d)
        return 词号_词次数表, 作者编号_词数表, 平均专家文本长度, 所有作者词总数

    def 获得作者稀疏tfidf向量(self, 作者号_词_词数广义表地址):
        作者编号_词号8tfidf表d = {}
        作者编号_词号8出现次数表d = {}
        作者编号_词总数表d = {}
        词号_被含作者广义表d = {}
        词号_idf表d = {}
        with open(作者号_词_词数广义表地址, 'r', encoding='utf-8') as r:
            for line in r:
                line = line.strip().split('\t')
                if len(line) < 2:
                    continue
                作者编号 = line[0]
                作者编号_词号8出现次数表d[作者编号] = {}
                作者编号_词总数表d[作者编号] = 0
                for 词号8出现次数 in line[1:]:
                    词号8出现次数 = 词号8出现次数.split(':')
                    词号 = int(词号8出现次数[0])
                    出现次数 = int(词号8出现次数[1])
                    作者编号_词号8出现次数表d[作者编号][词号] = 出现次数  # 作者编号_词号8t出现次数表d
                    作者编号_词总数表d[作者编号] += 出现次数  # 作者编号_词总数表d
                    if 词号 in 词号_被含作者广义表d:  # 词号_被含作者广义表d
                        词号_被含作者广义表d[词号][作者编号] = None
                    else:
                        词号_被含作者广义表d[词号] = {作者编号: None}
        作者数目 = len(作者编号_词总数表d)
        for 词号, 被含作者d in 词号_被含作者广义表d.items():
            词号_idf表d[词号] = math.log2(作者数目 / len(被含作者d))
        for 作者编号, 词号_出现次数表d in 作者编号_词号8出现次数表d.items():
            作者编号_词号8tfidf表d[作者编号] = {}
            for 词号, 出现次数 in 词号_出现次数表d.items():
                作者编号_词号8tfidf表d[作者编号][词号] = 出现次数 / 作者编号_词总数表d[作者编号] * 词号_idf表d[词号]
        return 作者编号_词号8tfidf表d, 词号_idf表d, 作者编号_词号8出现次数表d

    def 获得某作者的主题分布向量(self, 作者编号):
        主题分布向量l = self.作者_主题分布矩阵l[self.作者编号_作者序号表d[作者编号]]
        return 主题分布向量l

    def 计算某专家和某主题次数的覆盖结果(self, 专家编号, 主题次数向量, 测试论文时间, 半衰期=2, 专家次数同比缩减=False):
        专家主题_时间8出现次数矩阵l = self.专家_主题_时间8出现次数张量d[专家编号]
        专家主题_出现次数l = self.专家_主题_出现次数矩阵d[专家编号]
        if 专家次数同比缩减:
            专家论文数 = len(self.作者号_论文号字典[专家编号])
            专家主题_出现次数l = [i / 专家论文数 for i in 专家主题_出现次数l]

        全比例覆盖 = 覆盖或距离计算.覆盖度计算(专家主题_出现次数l, 主题次数向量)
        专家主题_累计时间出现次数l = [0] * len(专家主题_出现次数l)
        for i in range(len(专家主题_时间8出现次数矩阵l)):
            时间8出现次数 = 专家主题_时间8出现次数矩阵l[i]
            衰变累计次数 = 0
            for 时间, 出现次数 in 时间8出现次数.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计次数 += self._衰变函数(测试论文时间, 时间, 半衰期) * 出现次数
            专家主题_累计时间出现次数l[i] = 衰变累计次数
        最近时间覆盖 = 覆盖或距离计算.覆盖度计算(专家主题_累计时间出现次数l, 主题次数向量)
        覆盖上限 = 1
        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的覆盖结果(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        全比例覆盖 = 覆盖或距离计算.覆盖度计算(专家主题_分布概率l, 主题分布向量l)
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.覆盖度计算(专家主题_累计时间出现概率l, 主题分布向量l)
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的余弦距离(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.余弦相似度计算(专家主题_分布概率l, 主题分布向量l)
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.余弦相似度计算(专家主题_累计时间出现概率l, 主题分布向量l)
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的欧式距离(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.欧式相似度计算(专家主题_分布概率l, 主题分布向量l)
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.欧式相似度计算(专家主题_累计时间出现概率l, 主题分布向量l)
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的JS距离(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.JS相似度计算(专家主题_分布概率l, 主题分布向量l)
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.JS相似度计算(专家主题_累计时间出现概率l, 主题分布向量l)
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的NDCG距离(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.NDCG计算(专家主题_分布概率l, 主题分布向量l)
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.NDCG计算(专家主题_累计时间出现概率l, 主题分布向量l)
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家对稿件词向量的生成概率(self, 专家编号, 文本词号向量l, 主题词分布矩阵l, 测试论文时间, 半衰期):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.文档生成概率计算(专家主题_分布概率l, 主题词分布矩阵l, 文本词号向量l)
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率  # 归一化
        最近时间覆盖 = 覆盖或距离计算.文档生成概率计算(专家主题_累计时间出现概率l, 主题词分布矩阵l, 文本词号向量l)
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家对稿件词向量的tfidf余弦距离(self, 专家编号, 文本词号向量l):
        # 获取 词号向量的稀疏tfidf向量
        文本词号_tfidf表d = {}  # {文本词号:tfidf,..}
        文本词号_出现次数表d = dict(Counter(文本词号向量l))
        for 词号, 出现次数 in 文本词号_出现次数表d.items():
            文本词号_tfidf表d[词号] = 出现次数 / len(文本词号向量l) * self.词号_idf表d[词号]

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.稀疏向量余弦相似度计算(self.作者编号_词号8tfidf表d[专家编号], 文本词号_tfidf表d)
        # 计算 最近时间覆盖
        最近时间覆盖 = 全比例覆盖
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家对稿件词向量的LM距离(self, 专家编号, 文本词号向量l, topN排序值):
        文本词号_LM值表d = {}  # {文本词号:LM值,..}
        专家文本长度 = double(self.作者编号_词数表[专家编号])
        # 获取这个专家的 词号_LM值表d
        词号_LM值表d = {}

        # 开始计算
        for 一个词号 in 文本词号向量l:
            # 如果已经计算过
            if 一个词号 in 词号_LM值表d:
                文本词号_LM值表d[一个词号] = 词号_LM值表d[一个词号]
                continue
            # 没有计算过则计算
            if 一个词号 in self.作者编号_词号8出现次数表d[专家编号]:
                词在专家中出现次数 = self.作者编号_词号8出现次数表d[专家编号][一个词号]
            else:
                词在专家中出现次数 = 0
            词在所有专家中出现次数 = self.词号_词次数表[一个词号]
            LM值 = 词在专家中出现次数 / (专家文本长度 + self.平均专家文本长度) + \
                  (1 - 词在专家中出现次数 / (专家文本长度 + self.平均专家文本长度)) * 词在所有专家中出现次数 / self.所有作者词总数
            文本词号_LM值表d[一个词号] = LM值
            词号_LM值表d[一个词号] = LM值

        # 连乘
        if not self.去重复:
            文档LM值向量 = []
            for 一个词号 in 文本词号向量l:
                文档LM值向量.append(文本词号_LM值表d[一个词号])
            if topN排序值 > 0:
                文档LM值向量_排序 = sorted(文档LM值向量, reverse=True)
                文档LM值向量 = 文档LM值向量_排序[:topN排序值]
            总LM值 = self.初始总LM值
            for LM值 in 文档LM值向量:
                总LM值 *= LM值
        else:
            if topN排序值 > 0:
                文本词号_LM值表d_排序 = sorted(文本词号_LM值表d.items(), key=lambda t: t[1], reverse=True)
                文本词号_LM值表d = dict(文本词号_LM值表d_排序[:topN排序值])
            总LM值 = self.初始总LM值
            for _, LM值 in 文本词号_LM值表d.items():
                总LM值 = 总LM值 * LM值

        # 计算 全比例覆盖
        全比例覆盖 = 总LM值
        # 计算 最近时间覆盖
        最近时间覆盖 = 总LM值
        # 计算 覆盖上限
        覆盖上限 = 1
        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 计算某专家和某主题分布的逆序数COS距离(self, 专家编号, 主题分布向量l, 测试论文时间, 半衰期=2):
        专家主题_时间8分布矩阵l = self.专家_主题_时间8分布张量d[专家编号]
        专家主题_分布概率l = self.获得某作者的主题分布向量(专家编号)

        # 计算 全比例覆盖
        全比例覆盖 = 覆盖或距离计算.逆序数COS相似度(主题分布向量l, 专家主题_分布概率l)
        # 全比例覆盖=覆盖或距离计算.逆序数COS相似度(专家主题_分布概率l,主题分布向量l) # 用于逆序数反
        # 计算 最近时间覆盖
        专家主题_累计时间出现概率l = [0] * len(专家主题_分布概率l)
        总概率 = 0
        for i in range(len(专家主题_时间8分布矩阵l)):
            时间8主题概率 = 专家主题_时间8分布矩阵l[i]
            衰变累计 = 0
            for 时间, 主题概率 in 时间8主题概率.items():
                if 测试论文时间 >= 时间 and 时间 > 0:
                    衰变累计 += self._衰变函数(测试论文时间, 时间, 半衰期) * 主题概率
            专家主题_累计时间出现概率l[i] = 衰变累计
            总概率 += 衰变累计
        for i in range(len(专家主题_累计时间出现概率l)):
            if 总概率 > 0:
                专家主题_累计时间出现概率l[i] /= 总概率
        最近时间覆盖 = 覆盖或距离计算.逆序数COS相似度(主题分布向量l, 专家主题_累计时间出现概率l)
        # 最近时间覆盖=覆盖或距离计算.逆序数COS相似度(专家主题_累计时间出现概率l,主题分布向量l) # 用于逆序数反
        # 计算 覆盖上限
        覆盖上限 = 1

        return 覆盖上限, 最近时间覆盖, 全比例覆盖

    def 获取某个作者的所有文档编号(self, 作者编号):
        if 作者编号 in self.作者号_论文号字典:
            return self.作者号_论文号字典[作者编号]
        else:
            return None

    def 遍历作者(self):
        if self.作者遍历进度 >= len(self.作者向量l):
            return None
        self.作者遍历进度 += 1
        return self.作者向量l[self.作者遍历进度 - 1]

    def 重置遍历作者标记(self):
        self.作者遍历进度 = 0

    def 返回专家数量(self):
        return len(self.作者号_论文号字典)

    def 返回平均专家论文数(self):
        return self.平均专家论文数


class 专家论文:
    def __init__(self, 文档_主题分布地址, 论文号_作者号广义表地址, 文档号_词_词数广义表地址, 文档_主题_次数矩阵地址=None,
                 初始总LM值=1.0):
        文档_主题分布l = []
        论文号_作者号d = {}
        文档号_词数表l = []
        文档号_词号8出现次数表d = {}
        词号_词次数表d = {}
        所有文档词总数 = 0
        文档号_词数表d = {}
        文档号_主题次数分布表d = {}

        with open(文档_主题分布地址, encoding='utf-8') as 读取:
            for 一行 in 读取:
                if len(一行.strip()) == 0:
                    continue
                一行 = 一行.strip().split('\t')
                文档_主题分布l.append([float(i) for i in 一行])
        with open(论文号_作者号广义表地址, encoding='utf-8') as 读取:
            for 一行 in 读取:
                一行 = 一行.strip().split('\t')
                论文号_作者号d.update([(一行[0], 一行[1:])])
        with open(文档号_词_词数广义表地址, 'r', encoding='utf-8') as r:
            for line in r:
                line = line.strip().split('\t')
                if len(line) < 2:
                    continue
                文档号 = line[0]
                文档号_词号8出现次数表d[文档号] = {}
                词_次数表l = [[int(i.split(':')[0]), int(i.split(':')[1])] for i in line[1:]]
                总词数 = 0
                for 词, 次数 in 词_次数表l:
                    总词数 += 次数
                    文档号_词号8出现次数表d[文档号][词] = 次数
                    if 词 in 词号_词次数表d:
                        词号_词次数表d[词] += 次数
                    else:
                        词号_词次数表d[词] = 次数
                文档号_词数表l.append([文档号, 总词数])
                文档号_词数表d[文档号] = 总词数
                所有文档词总数 += 总词数
            平均文档长度 = 所有文档词总数 / len(文档号_词号8出现次数表d)
        文档_对应作者_主题次数_主题分布表d = {}
        for 第i文档 in range(len(文档_主题分布l)):
            文档号, 总词数 = 文档号_词数表l[第i文档]
            作者号l = 论文号_作者号d[文档号]
            主题分布l = 文档_主题分布l[第i文档]
            # 计算主题次数
            主题次数l = [0] * len(主题分布l)
            for i in range(len(主题分布l)):
                主题概率 = 主题分布l[i]
                主题次数l[i] = 主题概率 * 总词数
            文档_对应作者_主题次数_主题分布表d[文档号] = [作者号l, 主题次数l, 主题分布l]
        if 文档_主题_次数矩阵地址 != None and len(文档_主题_次数矩阵地址) > 0:
            with open(文档_主题_次数矩阵地址, 'r', encoding='utf-8') as r:
                文档序号 = 0
                for line in r:
                    if len(line.strip()) == 0:
                        continue
                    line = line.strip().split('\t')
                    文档编号 = 文档号_词数表l[文档序号][0]
                    文档号_主题次数分布表d[文档编号] = [int(i) for i in line]
                    文档序号 += 1

        self.文档号_词数表l = 文档号_词数表l  # 这个列表的顺序是和 文档主题分布 中文档的顺序是一致的
        self.文档_对应作者_主题次数_主题分布表d = 文档_对应作者_主题次数_主题分布表d
        self.文档号_主题次数分布表d = 文档号_主题次数分布表d
        self.文档号_词号8出现次数表d = 文档号_词号8出现次数表d
        self.平均文档长度 = 平均文档长度
        self.词号_词次数表d = 词号_词次数表d
        self.所有文档词总数 = 所有文档词总数
        self.文档号_词数表d = 文档号_词数表d
        self.初始总LM值 = 初始总LM值
        self.去重复 = True

        self.重置遍历论文标记()

    def 改变LM计算时是否去除重复词(self, 去重复=True):
        self.去重复 = 去重复

    def 返回某个文档的作者编号(self, 文档编号):
        if 文档编号 in self.文档_对应作者_主题次数_主题分布表d:
            return self.文档_对应作者_主题次数_主题分布表d[文档编号][0]
        else:
            return None

    def 返回某个文档的主题分布(self, 文档编号):
        if 文档编号 in self.文档_对应作者_主题次数_主题分布表d:
            return self.文档_对应作者_主题次数_主题分布表d[文档编号][2]
        else:
            return None

    def 遍历论文(self):
        if self.论文遍历进度 >= len(self.文档号_词数表l):
            return None
        self.论文遍历进度 += 1
        return self.文档号_词数表l[self.论文遍历进度 - 1][0]

    def 重置遍历论文标记(self):
        self.论文遍历进度 = 0

    def 计算某论文和主题次数的覆盖结果(self, 论文编号, 主题次数向量l):
        论文主题次数向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][1]
        覆盖比例 = 覆盖或距离计算.覆盖度计算(论文主题次数向量, 主题次数向量l)
        return 覆盖比例

    def 计算某论文和主题分布的覆盖结果(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.覆盖度计算(论文主题概率向量, 主题分布向量l)
        return 覆盖比例

    def 计算某论文和主题分布的余弦距离(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.余弦相似度计算(论文主题概率向量, 主题分布向量l)
        return 覆盖比例

    def 计算某论文和主题分布的欧式距离(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.欧式相似度计算(论文主题概率向量, 主题分布向量l)
        return 覆盖比例

    def 计算某论文和主题分布的JS距离(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.JS相似度计算(论文主题概率向量, 主题分布向量l)
        return 覆盖比例

    def 计算某论文和主题分布的NDCG距离(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.NDCG计算(论文主题概率向量, 主题分布向量l)
        return 覆盖比例

    def 计算某论文对稿件词向量的生成概率(self, 论文编号, 文本词号向量l, 主题词分布矩阵l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.文档生成概率计算(论文主题概率向量, 主题词分布矩阵l, 文本词号向量l)
        return 覆盖比例

    def 计算某论文对稿件词向量的LM距离(self, 论文编号, 文本词号向量l, topN排序值):
        文本词号_LM值表d = {}  # {文本词号:LM值,..}
        论文文本长度 = double(self.文档号_词数表d[论文编号])
        词号_LM值表d = {}

        for 一个词号 in 文本词号向量l:
            if 一个词号 in 词号_LM值表d:
                文本词号_LM值表d[一个词号] = 词号_LM值表d[一个词号]
                continue
            if 一个词号 in self.文档号_词号8出现次数表d[论文编号]:
                词在论文中出现次数 = self.文档号_词号8出现次数表d[论文编号][一个词号]
            else:
                词在论文中出现次数 = 0
            词在所有论文中出现次数 = self.词号_词次数表d[一个词号]
            LM值 = 词在论文中出现次数 / (论文文本长度 + self.平均文档长度) + \
                  (1 - 词在论文中出现次数 / (论文文本长度 + self.平均文档长度)) * 词在所有论文中出现次数 / self.所有文档词总数
            文本词号_LM值表d[一个词号] = LM值
            词号_LM值表d[一个词号] = LM值

        if not self.去重复:
            文档LM值向量 = []
            for 一个词号 in 文本词号向量l:
                文档LM值向量.append(文本词号_LM值表d[一个词号])
            if topN排序值 > 0:
                文档LM值向量_排序 = sorted(文档LM值向量, reverse=True)
                文档LM值向量 = 文档LM值向量_排序[:topN排序值]
            总LM值 = self.初始总LM值
            for LM值 in 文档LM值向量:
                总LM值 *= LM值
        else:
            if topN排序值 > 0:
                文本词号_LM值表d_排序 = sorted(文本词号_LM值表d.items(), key=lambda t: t[1], reverse=True)
                文本词号_LM值表d = dict(文本词号_LM值表d_排序[:topN排序值])
            总LM值 = self.初始总LM值
            for _, LM值 in 文本词号_LM值表d.items():
                总LM值 = 总LM值 * LM值

        return 总LM值

    def 计算某论文和主题分布的逆序数COS距离(self, 论文编号, 主题分布向量l):
        论文主题概率向量 = self.文档_对应作者_主题次数_主题分布表d[论文编号][2]
        覆盖比例 = 覆盖或距离计算.逆序数COS相似度(主题分布向量l, 论文主题概率向量)
        return 覆盖比例

    def 返回专家论文数量(self):
        return len(self.文档号_词数表d)


class 领域相似度计算方法():
    主题次数覆盖 = 1
    主题分布覆盖 = 2
    主题分布余弦距离 = 3
    稿件生成概率 = 4
    主题分布NDCG距离 = 5
    LM值 = 8
    逆序数COS距离 = 11
    主题分布欧式距离 = 12
    主题分布JS距离 = 13


class 评估:
    def __init__(self, c测试论文: 测试论文, c专家: 专家, c专家论文: 专家论文, 专家论文累计的半衰期, 测试论文时间统一置为=None,
                 领域相似度策略=领域相似度计算方法.主题分布覆盖, 迭代过程输出文件夹='', topN排序值=0,
                 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址='', 保存T读取F=True,
                 初始得分的附加计算参数d=None, topN=20):
        self.c测试论文 = c测试论文
        self.c专家 = c专家
        self.c专家论文 = c专家论文
        self.专家论文累计的半衰期 = 专家论文累计的半衰期
        self.topN = topN

        # 计算初始得分
        if 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址 != None and len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址) > 0:
            if 保存T读取F or not os.path.exists(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址):
                self._计算专家和论文的覆盖结果(专家论文累计的半衰期, 测试论文时间统一置为, 领域相似度策略, topN排序值)
                if 初始得分的附加计算参数d != None:
                    self.__初始得分的附加计算(**初始得分的附加计算参数d)
                print('保存初始迭代得分中...')
                二进制 = pickle.dumps(self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)
                with open(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址, 'wb') as w:
                    w.write(二进制)
            else:
                print('读取初始迭代得分中...')
                with open(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址, 'rb') as r:
                    self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l = pickle.load(r)
        else:
            self._计算专家和论文的覆盖结果(专家论文累计的半衰期, 测试论文时间统一置为, 领域相似度策略, topN排序值)
        self.稿件_专家_论文统计表l = []
        self.迭代过程输出文件夹 = 迭代过程输出文件夹

    def _计算专家和论文的覆盖结果(self, 半衰期, 测试论文时间统一置为, 领域相似度策略, topN排序值):
        测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l = []  # [[测试论文编号,[[专家编号1,覆盖上限,最近时间覆盖,平均],..],[[论文1,覆盖率],..],[专家编号1,..]],..]
        测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_用于合并 = []

        self.c测试论文.重置遍历标记()
        测试论文_时间_主题次数向量_答案专家_文本词号广义向量l = self.c测试论文.遍历测试论文()  # [论文编号,时间,主题次数向量l,专家编号向量l]
        计数 = 0
        while 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l != None:
            计数 += 1
            sys.stdout.write('\r')
            print('初始得分计算:开始第%d篇测试论文...' % 计数, end='')
            sys.stdout.flush()
            测试论文编号 = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[0]
            测试论文时间 = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[1]
            if isinstance(测试论文时间统一置为, int) and 测试论文时间统一置为 > 0:
                测试论文时间 = 测试论文时间统一置为
            测试论文主题次数向量l = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[2]
            测试论文答案专家向量l = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[3]
            测试论文文本词号向量l = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[4]
            测试论文主题分布向量l = self.c测试论文.获得稿件的主题分布向量l(测试论文编号)

            测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l.append([测试论文编号, [], [], 测试论文答案专家向量l])

            # 计算专家覆盖结果
            self.c专家.重置遍历作者标记()
            专家编号 = self.c专家.遍历作者()
            while 专家编号 != None:
                覆盖上限, 最近时间覆盖, 全比例覆盖 = 0, 0, 0
                # 策略选择
                if 领域相似度策略 == 领域相似度计算方法.主题次数覆盖:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题次数的覆盖结果(专家编号, 测试论文主题次数向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布覆盖:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的覆盖结果(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布余弦距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的余弦距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布欧式距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的欧式距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布JS距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的JS距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.逆序数COS距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的逆序数COS距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布NDCG距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家和某主题分布的NDCG距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.稿件生成概率:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家对稿件词向量的生成概率(专家编号, 测试论文文本词号向量l, self.c测试论文.主题_词分布矩阵l, 测试论文时间,
                                                                    半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.LM值:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = self.c专家.计算某专家对稿件词向量的LM距离(专家编号, 测试论文文本词号向量l, topN排序值)

                if 领域相似度策略 != 领域相似度计算方法.LM值 and topN排序值 > 0:
                    LM距离 = self.c专家.计算某专家对稿件词向量的LM距离(专家编号, 测试论文文本词号向量l, topN排序值)
                    最近时间覆盖 = 最近时间覆盖 * LM距离[1]
                    全比例覆盖 = 全比例覆盖 * LM距离[2]
                    # if 全比例覆盖>0:全比例覆盖=1/(math.log10(1/全比例覆盖)+1)

                测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[-1][1].append([专家编号, 覆盖上限, 最近时间覆盖, 全比例覆盖])
                专家编号 = self.c专家.遍历作者()
            # 计算专家论文覆盖结果
            self.c专家论文.重置遍历论文标记()
            论文编号 = self.c专家论文.遍历论文()
            while 论文编号 != None:
                覆盖结果 = 0
                # 策略选择
                if 领域相似度策略 == 领域相似度计算方法.主题次数覆盖:
                    覆盖结果 = self.c专家论文.计算某论文和主题次数的覆盖结果(论文编号, 测试论文主题次数向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布覆盖:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的覆盖结果(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布余弦距离:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的余弦距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布欧式距离:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的欧式距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布JS距离:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的JS距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.逆序数COS距离:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的逆序数COS距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布NDCG距离:
                    覆盖结果 = self.c专家论文.计算某论文和主题分布的NDCG距离(论文编号, 测试论文主题分布向量l)
                    # 覆盖结果 = self.c专家论文.计算某论文和主题分布的余弦距离(论文编号, 测试论文主题分布向量l) # 文档之间不需要NDCG
                elif 领域相似度策略 == 领域相似度计算方法.稿件生成概率:
                    覆盖结果 = self.c专家论文.计算某论文对稿件词向量的生成概率(论文编号, 测试论文文本词号向量l, self.c测试论文.主题_词分布矩阵l)
                elif 领域相似度策略 == 领域相似度计算方法.LM值:
                    覆盖结果 = self.c专家论文.计算某论文对稿件词向量的LM距离(论文编号, 测试论文文本词号向量l, topN排序值)

                if 领域相似度策略 != 领域相似度计算方法.LM值 and topN排序值 > 0:
                    LM距离 = self.c专家论文.计算某论文对稿件词向量的LM距离(论文编号, 测试论文文本词号向量l, topN排序值)
                    覆盖结果 = 覆盖结果 * LM距离
                    # 覆盖结果 = (2-覆盖结果)**0.5*覆盖结果**0.5 # (1-(1-覆盖结果)**2)**1/2
                    # if 覆盖结果>0:覆盖结果=1/(math.log10(1/覆盖结果)+1)

                测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[-1][2].append([论文编号, 覆盖结果])
                论文编号 = self.c专家论文.遍历论文()
            测试论文_时间_主题次数向量_答案专家_文本词号广义向量l = self.c测试论文.遍历测试论文()
        sys.stdout.write('\r')
        # 对齐专家和专家论文的相似度结果
        # self._对齐专家和专家论文的相似度结果(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)

        self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l

    def _按排名合并top(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_主, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_次, top, 专家第几值=3):
        序号 = 0
        for _, 专家得分表l_主, _, _ in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_主:
            专家得分表l_次 = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_次[序号][1]
            # 开始合并
            专家得分表l_主_排序 = sorted(专家得分表l_主, key=lambda t: t[专家第几值], reverse=True)
            专家得分表l_次_排序 = sorted(专家得分表l_次, key=lambda t: t[专家第几值], reverse=True)
            专家top编号集合 = set(i[0] for i in 专家得分表l_主_排序[:top]) | set(i[0] for i in 专家得分表l_次_排序[:top])
            专家top编号_主排名8词排名d = {}
            # 获得专家在不同结果中的排名
            计数 = 0
            for i in 专家得分表l_主_排序:
                编号 = i[0]
                if 编号 in 专家top编号集合:
                    if 编号 in 专家top编号_主排名8词排名d:
                        专家top编号_主排名8词排名d[编号][0] = 计数
                    else:
                        专家top编号_主排名8词排名d[编号] = [计数, None]
                计数 += 1
            计数 = 0
            for i in 专家得分表l_次_排序:
                编号 = i[0]
                if 编号 in 专家top编号集合:
                    专家top编号_主排名8词排名d[编号][1] = 计数
                计数 += 1
            # 按最差排名淘汰
            专家top编号_最终排序 = sorted(专家top编号_主排名8词排名d.items(), key=lambda t: (max(t[1]), min(t[1])))[:top]
            # 调整 专家得分表l_主_排序 分数
            专家top编号_最终排序_集合 = set(i[0] for i in 专家top编号_最终排序)
            专家编号全新排序 = [[i[0], None] for i in 专家top编号_最终排序]
            for i in range(len(专家得分表l_主_排序)):
                编号 = 专家得分表l_主_排序[i][0]
                得分 = 专家得分表l_主_排序[i][专家第几值]
                if 编号 not in 专家top编号_最终排序_集合:
                    专家编号全新排序.append([编号, None])
                专家编号全新排序[i][1] = 得分
            专家编号_得分d = dict(专家编号全新排序)
            for i in 专家得分表l_主:
                i[专家第几值] = 专家编号_得分d[i[0]]
            序号 += 1

    def _分数得分平衡合并(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_主, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_次):

        def 合并操作(主表l, 次表l, 主合并列, 次合并列):
            主表l_排序 = sorted(主表l, key=lambda t: t[主合并列], reverse=True)
            次表l_排序 = sorted(次表l, key=lambda t: t[次合并列], reverse=True)
            编号_主表d = {i[0]: i for i in 主表l_排序}  # 使用这个修改得分
            编号_修改后得分 = {}  # 记录后统一修改
            for i in range(len(主表l_排序)):
                得分 = 主表l_排序[i][主合并列] * 次表l_排序[i][次合并列]
                编号1 = 主表l_排序[i][0]
                编号2 = 次表l_排序[i][0]
                if 编号1 not in 编号_修改后得分:
                    编号_修改后得分[编号1] = 得分
                if 编号2 not in 编号_修改后得分:
                    编号_修改后得分[编号2] = 得分
            # 写回编号
            for 编号, 得分 in 编号_修改后得分.items():
                编号_主表d[编号][主合并列] = 得分

        序号 = 0
        for _, 专家得分表l_主, 专家论文得分表l_主, _ in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_主:
            专家得分表l_次 = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_次[序号][1]
            专家论文得分表l_次 = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_次[序号][2]
            # 开始合并
            合并操作(专家得分表l_主, 专家得分表l_次, 1, 1)
            合并操作(专家得分表l_主, 专家得分表l_次, 2, 2)
            合并操作(专家得分表l_主, 专家得分表l_次, 3, 3)
            合并操作(专家论文得分表l_主, 专家论文得分表l_次, 1, 1)
            序号 += 1

    def __初始得分的附加计算(self, 领域相似度策略, topN排序值, 测试论文_obj, 专家_obj, 专家论文_obj, 附加算法):
        半衰期 = self.专家论文累计的半衰期
        测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l = self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l
        测试论文编号_序号表d = {测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[i][0]: i for i in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l))}
        测试论文_obj.重置遍历标记()
        测试论文_时间_主题次数向量_答案专家_文本词号广义向量l = 测试论文_obj.遍历测试论文()  # [论文编号,时间,主题次数向量l,专家编号向量l]
        计数 = 0
        while 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l != None:
            计数 += 1
            sys.stdout.write('\r')
            print('初始得分的附加计算:开始第%d篇测试论文...' % 计数, end='')
            sys.stdout.flush()
            测试论文编号 = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[0]
            assert 测试论文编号 in 测试论文编号_序号表d, '附加"测试论文_obj"的测试论文不匹配!'
            序号 = 测试论文编号_序号表d[测试论文编号]
            测试论文时间 = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[1]
            测试论文主题次数向量l = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[2]
            测试论文文本词号向量l = 测试论文_时间_主题次数向量_答案专家_文本词号广义向量l[4]
            测试论文主题分布向量l = 测试论文_obj.获得稿件的主题分布向量l(测试论文编号)

            # 计算专家覆盖结果
            for 专家覆盖结果l in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[序号][1]:
                专家编号 = 专家覆盖结果l[0]
                覆盖上限, 最近时间覆盖, 全比例覆盖 = 0, 0, 0
                # 策略选择
                if 领域相似度策略 == 领域相似度计算方法.主题次数覆盖:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题次数的覆盖结果(专家编号, 测试论文主题次数向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布覆盖:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题分布的覆盖结果(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布余弦距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题分布的余弦距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布欧式距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题分布的欧式距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布JS距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题分布的JS距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布NDCG距离:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家和某主题分布的NDCG距离(专家编号, 测试论文主题分布向量l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.稿件生成概率:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家对稿件词向量的生成概率(专家编号, 测试论文文本词号向量l, 测试论文_obj.主题_词分布矩阵l, 测试论文时间, 半衰期)
                elif 领域相似度策略 == 领域相似度计算方法.LM值:
                    覆盖上限, 最近时间覆盖, 全比例覆盖 = 专家_obj.计算某专家对稿件词向量的LM距离(专家编号, 测试论文文本词号向量l, topN排序值)

                if 领域相似度策略 != 领域相似度计算方法.LM值 and topN排序值 > 0:
                    LM距离 = 专家_obj.计算某专家对稿件词向量的LM距离(专家编号, 测试论文文本词号向量l, topN排序值)
                    最近时间覆盖 = 最近时间覆盖 * LM距离[1]
                    全比例覆盖 = 全比例覆盖 * LM距离[2]

                # 开始计算新加得分和已有得分的整合结果
                专家覆盖结果l[1] = 附加算法(专家覆盖结果l[1], 覆盖上限)
                专家覆盖结果l[2] = 附加算法(专家覆盖结果l[2], 最近时间覆盖)
                专家覆盖结果l[3] = 附加算法(专家覆盖结果l[3], 全比例覆盖)
            # 计算专家论文覆盖结果
            for 专家论文覆盖结果l in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[序号][2]:
                论文编号 = 专家论文覆盖结果l[0]
                覆盖结果 = 0
                # 策略选择
                if 领域相似度策略 == 领域相似度计算方法.主题次数覆盖:
                    覆盖结果 = 专家论文_obj.计算某论文和主题次数的覆盖结果(论文编号, 测试论文主题次数向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布覆盖:
                    覆盖结果 = 专家论文_obj.计算某论文和主题分布的覆盖结果(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布余弦距离:
                    覆盖结果 = 专家论文_obj.计算某论文和主题分布的余弦距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布欧式距离:
                    覆盖结果 = 专家论文_obj.计算某论文和主题分布的欧式距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布JS距离:
                    覆盖结果 = 专家论文_obj.计算某论文和主题分布的JS距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.主题分布NDCG距离:
                    覆盖结果 = 专家论文_obj.计算某论文和主题分布的NDCG距离(论文编号, 测试论文主题分布向量l)
                elif 领域相似度策略 == 领域相似度计算方法.稿件生成概率:
                    覆盖结果 = 专家论文_obj.计算某论文对稿件词向量的生成概率(论文编号, 测试论文文本词号向量l, 测试论文_obj.主题_词分布矩阵l)
                elif 领域相似度策略 == 领域相似度计算方法.LM值:
                    覆盖结果 = 专家论文_obj.计算某论文对稿件词向量的LM距离(论文编号, 测试论文文本词号向量l, topN排序值)

                if 领域相似度策略 != 领域相似度计算方法.LM值 and topN排序值 > 0:
                    LM距离 = 专家论文_obj.计算某论文对稿件词向量的LM距离(论文编号, 测试论文文本词号向量l, topN排序值)
                    覆盖结果 = 覆盖结果 * LM距离

                # 开始计算新加得分和已有得分的整合结果
                专家论文覆盖结果l[1] = 附加算法(专家论文覆盖结果l[1], 覆盖结果)
            测试论文_时间_主题次数向量_答案专家_文本词号广义向量l = 测试论文_obj.遍历测试论文()
        sys.stdout.write('\r')

    def _对齐专家和专家论文的相似度结果(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l):
        专家结果最大值 = [[0, 0, 0] for i in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l))]
        专家论文结果最大值 = [0] * len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)
        # 寻找最大值
        for i in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)):
            专家覆盖结果l = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[i][1]
            论文覆盖结果l = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[i][2]
            for 专家编号, 覆盖上限, 最近时间覆盖, 全比例覆盖 in 专家覆盖结果l:
                if 专家结果最大值[i][0] < 覆盖上限:
                    专家结果最大值[i][0] = 覆盖上限
                if 专家结果最大值[i][1] < 最近时间覆盖:
                    专家结果最大值[i][1] = 最近时间覆盖
                if 专家结果最大值[i][2] < 全比例覆盖:
                    专家结果最大值[i][2] = 全比例覆盖
            for 论文编号, 覆盖结果 in 论文覆盖结果l:
                if 专家论文结果最大值[i] < 覆盖结果:
                    专家论文结果最大值[i] = 覆盖结果
        for i in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)):
            专家覆盖结果l = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[i][1]
            论文覆盖结果l = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[i][2]
            for j in range(len(专家覆盖结果l)):
                专家覆盖结果l[j][1] /= 专家结果最大值[i][0]
                专家覆盖结果l[j][2] /= 专家结果最大值[i][1]
                专家覆盖结果l[j][3] /= 专家结果最大值[i][2]
            for j in range(len(论文覆盖结果l)):
                论文覆盖结果l[j][1] /= 专家论文结果最大值[i]

    @staticmethod
    def 评估测试论文结果(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, N, 选择专家覆盖结果的第几个=3, 展示指标=[0, 0, 0, 1, 1, 1, 0, 0, 0, 0]):
        文档索引_计算排名_作者号矩阵 = []
        文档索引_标准排名_作者号矩阵 = []
        for 测试论文, 专家覆盖结果表l, 论文覆盖结果表l, 答案专家向量l in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l:
            专家覆盖结果表l排序 = sorted(专家覆盖结果表l, key=lambda t: t[选择专家覆盖结果的第几个], reverse=True)
            文档索引_计算排名_作者号矩阵.append([i[0] for i in 专家覆盖结果表l排序[:N]])
            文档索引_标准排名_作者号矩阵.append(答案专家向量l)
        返回值 = []
        展示指标 += [0] * 50
        if 展示指标[0] == 1:
            P_N = 处理11.计算多文档P_N指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(sum(P_N) / len(P_N))
        if 展示指标[1] == 1:
            MAP = 处理11.计算MAP指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(MAP)
        if 展示指标[2] == 1:
            NDCG = 处理11.计算多文档NDCG指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(sum(NDCG) / len(NDCG))
        if 展示指标[3] == 1:
            正确率 = 处理11.计算多文档正确率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(正确率)
        if 展示指标[4] == 1:
            召回率 = 处理11.计算多文档召回率(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(召回率)
        if 展示指标[5] == 1:
            Fbeta = 处理11.计算多文档Fbeta指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(Fbeta)
        if 展示指标[6] == 1:
            反Fbeta = 处理11.计算多文档反Fbeta指标(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(反Fbeta)
        if 展示指标[7] == 1:
            指标 = 处理11.MAP_相关文档数为N(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(指标)
        if 展示指标[8] == 1:
            指标 = 处理11.NDCG_无序(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(指标)
        if 展示指标[9] == 1:
            指标 = 处理11.Bpref_相关文档数为N(文档索引_计算排名_作者号矩阵, 文档索引_标准排名_作者号矩阵, N)
            返回值.append(指标)
        return 返回值

    def _输出统计迭代结果(self, 稿件_专家_论文统计表l, 输出文件目录, 非迭代元素个数=3,
                  专家文件表头="专家编号\t论文数\t答案专家\t答案专家数",
                  专家论文文件表头="专家论文编号\t专家数\t答案专家论文\t答案专家论文数"):
        if len(稿件_专家_论文统计表l) < 1 or 输出文件目录 == None or len(输出文件目录) < 1:
            return False
        if not os.path.exists(输出文件目录):
            os.makedirs(输出文件目录)
        for 稿件编号, 专家统计情况d, 专家论文统计情况d in 稿件_专家_论文统计表l:
            文件目录_专家 = 输出文件目录 + '/' + '稿件=%s_专家情况.txt' % str(稿件编号)
            文件目录_专家论文 = 输出文件目录 + '/' + '稿件=%s_专家论文情况.txt' % str(稿件编号)

            专家迭代次数 = len(取字典第一个(专家统计情况d)[1]) - 非迭代元素个数  # 第一次是不迭代情况
            专家论文迭代次数 = len(取字典第一个(专家论文统计情况d)[1]) - 非迭代元素个数  # 第一次是不迭代情况
            专家文件表头 = 专家文件表头 + ''.join(['\t得分\t%d-名次\t名次变化' % (i) for i in range(专家迭代次数)])
            专家论文文件表头 = 专家论文文件表头 + ''.join(['\t得分\t%d-名次\t名次变化' % (i) for i in range(专家论文迭代次数)])

            with open(文件目录_专家, 'w', encoding='utf-8') as w:
                w.write(专家文件表头 + '\r\n')
                for 专家编号, 专家情况l in 专家统计情况d.items():
                    w.write(专家编号 + '\t' + '\t'.join([str(i) for i in 专家情况l[:非迭代元素个数]]) + '\t')
                    w.write('\t'.join(['%e\t%d\t%d' % (i[0], i[1], i[2]) for i in 专家情况l[非迭代元素个数:]]))
                    w.write('\r\n')
            with open(文件目录_专家论文, 'w', encoding='utf-8') as w:
                w.write(专家论文文件表头 + '\r\n')
                for 专家论文编号, 专家论文情况l in 专家论文统计情况d.items():
                    w.write(专家论文编号 + '\t' + '\t'.join([str(i) for i in 专家论文情况l[:非迭代元素个数]]) + '\t')
                    w.write('\t'.join(['%e\t%d\t%d' % (i[0], i[1], i[2]) for i in 专家论文情况l[非迭代元素个数:]]))
                    w.write('\r\n')
        return True

    def _统计迭代情况(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, 稿件_专家_论文统计表l, 取专家第几个值=2):
        if len(稿件_专家_论文统计表l) < 1:
            for 第i测试论文 in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)):
                稿件编号 = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][0]
                专家表l = [i[0] for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][1]]
                专家论文表l = [i[0] for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][2]]
                答案专家向量s = {i for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][3]}
                答案专家论文向量s = set()

                专家统计情况d = {}
                专家论文统计情况d = {}
                for 专家编号 in 专家表l:
                    专家丨论文编号表l = self.c专家.获取某个作者的所有文档编号(专家编号)
                    专家论文数 = len(专家丨论文编号表l)
                    if 专家编号 in 答案专家向量s:
                        是否为答案专家 = True
                        答案专家论文向量s = 答案专家论文向量s | set(专家丨论文编号表l)
                    else:
                        是否为答案专家 = False
                    专家统计情况d[专家编号] = [专家论文数, 是否为答案专家, len(答案专家向量s)]
                for 专家论文编号 in 专家论文表l:
                    专家论文丨专家编号表l = self.c专家论文.返回某个文档的作者编号(专家论文编号)
                    专家数 = len(专家论文丨专家编号表l)
                    if 专家论文编号 in 答案专家论文向量s:
                        是否为答案专家论文 = True
                    else:
                        是否为答案专家论文 = False
                    专家论文统计情况d[专家论文编号] = [专家数, 是否为答案专家论文, len(答案专家论文向量s)]
                稿件_专家_论文统计表l.append([稿件编号, 专家统计情况d, 专家论文统计情况d])
        # 准备统计分数和排名
        稿件编号_专家得分情况表d = {}  # {稿件编号:专家编号_得分8排名8名次变化表d,..}
        稿件编号_专家论文得分情况表d = {}  # {稿件编号:专家论文编号_得分8排名8名次变化表d,..}
        for 第i测试论文 in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)):
            稿件编号 = 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][0]
            专家_结果表l = [(i[0], i[取专家第几个值 + 1]) for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][1]]
            专家论文_结果表l = [(i[0], i[1]) for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][2]]
            稿件编号_专家得分情况表d[稿件编号] = self._统计迭代中的分数排名(专家_结果表l)
            稿件编号_专家论文得分情况表d[稿件编号] = self._统计迭代中的分数排名(专家论文_结果表l)

        # 开始统计分数和排名
        for 稿件编号, 专家统计情况d, 专家论文统计情况d in 稿件_专家_论文统计表l:
            专家编号_得分8排名8名次变化表d = 稿件编号_专家得分情况表d[稿件编号]
            专家论文编号_得分8排名8名次变化表d = 稿件编号_专家论文得分情况表d[稿件编号]
            # 开始统计专家的得分和排名
            for 专家编号, 专家情况l in 专家统计情况d.items():
                得分8排名8名次变化 = 专家编号_得分8排名8名次变化表d[专家编号]
                if isinstance(专家情况l[-1], list):
                    上一次排名 = 专家情况l[-1][1]
                else:
                    上一次排名 = 得分8排名8名次变化[1]
                得分8排名8名次变化[2] = 上一次排名 - 得分8排名8名次变化[1]
                专家情况l.append(得分8排名8名次变化)
            # 开始统计专家论文的得分和排名
            for 专家论文编号, 专家论文情况l in 专家论文统计情况d.items():
                得分8排名8名次变化 = 专家论文编号_得分8排名8名次变化表d[专家论文编号]
                if isinstance(专家论文情况l[-1], list):
                    上一次排名 = 专家论文情况l[-1][1]
                else:
                    上一次排名 = 得分8排名8名次变化[1]
                得分8排名8名次变化[2] = 上一次排名 - 得分8排名8名次变化[1]
                专家论文情况l.append(得分8排名8名次变化)
        return 稿件_专家_论文统计表l

    def _统计迭代中的分数排名(self, 编号_得分表l):
        编号_得分8排名8零表d = {}  # {编号:[得分,排名,0],..}
        for 编号, 得分 in 编号_得分表l:
            编号_得分8排名8零表d[编号] = [得分, 0, 0]
        编号_得分8排名8零表d_排名 = sorted(编号_得分8排名8零表d.items(), key=lambda t: t[1][0], reverse=True)
        for i in range(len(编号_得分8排名8零表d_排名)):
            编号 = 编号_得分8排名8零表d_排名[i][0]
            编号_得分8排名8零表d[编号][1] = i + 1
        return 编号_得分8排名8零表d

    def 迭代一次(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, 速度参数_专家论文=0.5, 速度参数_专家=0.5,
             迭代累加方式=迭代周围得分方式.衰减求和):
        测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后 = copy.deepcopy(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)

        for 第i测试论文 in range(len(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l)):
            专家_覆盖结果表d = {i[0]: i[1:] for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][1]}
            论文_覆盖结果表d = {i[0]: i[1] for i in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l[第i测试论文][2]}
            专家_覆盖结果表d_迭代后 = copy.deepcopy(专家_覆盖结果表d)
            论文_覆盖结果表d_迭代后 = copy.deepcopy(论文_覆盖结果表d)

            # 用专家论文迭代专家
            for 专家编号, 最大_最近时间_平均覆盖 in 专家_覆盖结果表d.items():
                专家论文覆盖率向量l = [论文_覆盖结果表d[i] for i in self.c专家.获取某个作者的所有文档编号(专家编号)]
                if len(专家论文覆盖率向量l) > 0:
                    r = (1 - 速度参数_专家论文) * 最大_最近时间_平均覆盖[2] + 速度参数_专家论文 * 迭代累加方式(专家论文覆盖率向量l)
                    专家_覆盖结果表d_迭代后[专家编号][2] = r

            # 用专家迭代专家论文
            for 论文编号, 论文覆盖率 in 论文_覆盖结果表d.items():
                专家覆盖率向量l = [专家_覆盖结果表d[i][2] for i in self.c专家论文.返回某个文档的作者编号(论文编号)]
                if len(专家覆盖率向量l) > 0:
                    r = (1 - 速度参数_专家) * 论文覆盖率 + 速度参数_专家 * 迭代累加方式(专家覆盖率向量l)
                    论文_覆盖结果表d_迭代后[论文编号] = r

            测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后[第i测试论文][1] = [[i] + j for i, j in 专家_覆盖结果表d_迭代后.items()]
            测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后[第i测试论文][2] = [[i, j] for i, j in 论文_覆盖结果表d_迭代后.items()]
        return 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后

    def 多次迭代并评估(self, 迭代次数, topN, 速度参数_专家论文=0.5, 速度参数_专家=0.5, 迭代累加方式=迭代周围得分方式.衰减求和, 展示指标=[0, 0, 0, 1, 1, 1, 0, 0, 0, 0],
                平均化处理对象=0, 迭代后平均化处理=False, 最优预测结果保存地址='',
                评分矩阵输出地址='', 最优评分矩阵输出地址='', 评分矩阵选择专家覆盖结果的第几个=3):
        # 无迭代时
        指标 = []
        if 展示指标[0] == 1:
            指标.append('P_N')
        if 展示指标[1] == 1:
            指标.append('MAP')
        if 展示指标[2] == 1:
            指标.append('NDCG')
        if 展示指标[3] == 1:
            指标.append('正确率')
        if 展示指标[4] == 1:
            指标.append('召回率')
        if 展示指标[5] == 1:
            指标.append('Fbeta')
        if 展示指标[6] == 1:
            指标.append('反Fbeta')
        if 展示指标[7] == 1:
            指标.append('MAP')
        if 展示指标[8] == 1:
            指标.append('NDCG')
        if 展示指标[9] == 1:
            指标.append('Bpref')
        print('指标\t' + '\t'.join(指标))
        覆盖上限结果l = self.评估测试论文结果(self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, topN, 1, 展示指标=展示指标)
        print('覆盖上限\t%s' % ('\t'.join([str(i) for i in 覆盖上限结果l])))
        最近时间覆盖结果l = self.评估测试论文结果(self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, topN, 2, 展示指标=展示指标)
        print('最近时间覆盖结果\t%s' % ('\t'.join([str(i) for i in 最近时间覆盖结果l])))
        平均覆盖结果l = self.评估测试论文结果(self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, topN, 展示指标=展示指标)
        print('0次迭代结果\t%s' % ('\t'.join([str(i) for i in 平均覆盖结果l])))
        测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后 = self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l
        最优结果l = copy.deepcopy(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后)
        上一次结果 = 平均覆盖结果l[sum(展示指标[:3])]  # WSIM使用的是平均覆盖结果
        # 记录得分
        if self.迭代过程输出文件夹 != None and len(self.迭代过程输出文件夹) > 0:
            self._统计迭代情况(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, self.稿件_专家_论文统计表l)
        # 初始相似度平均化处理
        self._评估结果_相似度平均化处理(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, topN, 平均化处理对象)
        # 迭代后结果
        for 第n次迭代 in range(迭代次数):
            测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后 = \
                self.迭代一次(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, 速度参数_专家论文, 速度参数_专家, 迭代累加方式)
            迭代结果l = self.评估测试论文结果(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, topN, 展示指标=展示指标)
            print('%d次迭代结果\t%s' % (第n次迭代 + 1, '\t'.join([str(i) for i in 迭代结果l])))
            这一次结果 = 迭代结果l[sum(展示指标[:3])]  # 数字代表使用正确率为指标
            if 这一次结果 > 上一次结果:
                上一次结果 = 这一次结果
                最优结果l = copy.deepcopy(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后)
            if self.迭代过程输出文件夹 != None and len(self.迭代过程输出文件夹) > 0:
                self._统计迭代情况(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, self.稿件_专家_论文统计表l)
            if 迭代后平均化处理:
                self._评估结果_相似度平均化处理(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l_迭代后, topN, 平均化处理对象)
        self._输出统计迭代结果(self.稿件_专家_论文统计表l, self.迭代过程输出文件夹)
        if 最优预测结果保存地址 != None and len(最优预测结果保存地址) > 0:
            print('使用正确率作为指标输出最优结果(%f)...' % 上一次结果)
            self._输出预测结果(最优结果l, 最优预测结果保存地址, topN, 处理11.计算正确率, 专家映射论文f=self.c专家.获取某个作者的所有文档编号)
        if 评分矩阵输出地址 != None and len(评分矩阵输出地址) > 0:
            专家输出地址 = insertToModifyFileName('_专家', 评分矩阵输出地址)
            专家论文输出地址 = insertToModifyFileName('_专家论文', 评分矩阵输出地址)
            self.输出评分矩阵(self.测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, 专家输出地址, 专家论文输出地址, 评分矩阵选择专家覆盖结果的第几个)
        if 最优评分矩阵输出地址 != None and len(最优评分矩阵输出地址) > 0:  # 多次迭代后的
            专家输出地址 = insertToModifyFileName('_专家', 最优评分矩阵输出地址)
            专家论文输出地址 = insertToModifyFileName('_专家论文', 最优评分矩阵输出地址)
            self.输出评分矩阵(最优结果l, 专家输出地址, 专家论文输出地址, 评分矩阵选择专家覆盖结果的第几个)
        return 上一次结果

    @staticmethod
    def 输出评分矩阵(测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, 专家输出地址, 专家论文输出地址=None, 选择专家覆盖结果的第几个=3):
        专家输出 = open(专家输出地址, 'w', encoding='utf-8')
        if 专家论文输出地址:
            专家论文输出 = open(专家论文输出地址, 'w', encoding='utf-8')
        for 测试论文编号, 专家覆盖结果l, 论文覆盖结果l, _ in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l:
            专家编号_得分 = [(i[0], i[选择专家覆盖结果的第几个]) for i in 专家覆盖结果l]
            专家编号_得分 = sorted(专家编号_得分, key=lambda t: t[1], reverse=True)
            专家论文编号_得分 = sorted(论文覆盖结果l, key=lambda t: t[1], reverse=True)
            专家输出.write(测试论文编号 + '\t')
            专家输出.write('\t'.join(['%s\t%e' % (i[0], i[1]) for i in 专家编号_得分]))
            专家输出.write('\r\n')
            if 专家论文输出地址:
                专家论文输出.write(测试论文编号 + '\t')
                专家论文输出.write('\t'.join(['%s\t%e' % (i[0], i[1]) for i in 专家论文编号_得分]))
                专家论文输出.write('\r\n')
        专家输出.close()
        if 专家论文输出地址:
            专家论文输出.close()

    def _输出预测结果(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, 输出文件地址, topN, 指标计算算法, 选择专家覆盖结果的第几个=3,
                专家映射论文f=None):
        if 输出文件地址 == None or len(输出文件地址) == 0:
            return False
        测试论文编号_结果表l = []
        for 测试论文编号, 专家覆盖结果l, 论文覆盖结果l, 答案专家l in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l:
            排序结果 = sorted(专家覆盖结果l, key=lambda t: t[选择专家覆盖结果的第几个], reverse=True)
            预测专家编号l = [i[0] for i in 排序结果[:topN]]
            指标 = 指标计算算法(预测专家编号l, 答案专家l, topN)

            测试论文编号_结果表l.append([[测试论文编号, str(指标), str(len(答案专家l))]])

            答案专家s = set(答案专家l)
            论文覆盖结果d = dict(论文覆盖结果l)
            for i in 预测专家编号l:
                测试论文编号_结果表l[-1].append([i])  # 加入预测专家
                测试论文编号_结果表l[-1][-1].append('1' if i in 答案专家s else '0')  # 是否为答案
                if 专家映射论文f:
                    for 专家论文编号 in 专家映射论文f(i):
                        if 专家论文编号 in 论文覆盖结果d:
                            测试论文编号_结果表l[-1][-1].append(专家论文编号)
                            测试论文编号_结果表l[-1][-1].append('%e' % (论文覆盖结果d[专家论文编号]))

        with open(输出文件地址, 'w', encoding='utf-8') as w:
            for 一组预测结果 in 测试论文编号_结果表l:
                for i in 一组预测结果:
                    w.write('\t'.join(i) + '\r\n')
        return True

    def _评估结果_相似度平均化处理(self, 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l, topN, 平均化处理对象):
        if 平均化处理对象 > 0:
            for 每篇稿件评估结果 in 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l:
                if 平均化处理对象 & 1 == 1:
                    专家_每段长度 = topN
                    self._相似度平均化处理(每篇稿件评估结果[1], 3, 专家_每段长度)
                elif 平均化处理对象 & 2 == 2:
                    # 专家论文_每段长度=int(self.c专家论文.返回专家论文数量()/self.c专家.返回专家数量()*topN*2)
                    专家论文_每段长度 = int(self.c专家.返回平均专家论文数() * topN)
                    self._相似度平均化处理(每篇稿件评估结果[2], 1, 专家论文_每段长度)
        return 测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l

    def _相似度平均化处理(self, 向量组, 针对向量第几维平均化, 每段长度, 在原向量组上修改=True):
        if 0 < 每段长度 < 1:
            每段长度 = int(len(向量组) * 每段长度)
        elif 每段长度 == 1 or 每段长度 <= 0:
            return 向量组
        总段数 = int(len(向量组) / 每段长度)
        if len(向量组) % 每段长度 != 0:
            总段数 += 1
            最后一段长度 = len(向量组) % 每段长度
        else:
            最后一段长度 = 每段长度
        if not 在原向量组上修改:
            向量组 = copy.deepcopy(向量组)
        向量组_排序 = sorted(向量组, key=lambda t: t[针对向量第几维平均化], reverse=True)
        for i in range(总段数 - 1):
            每段总和 = sum([j[针对向量第几维平均化] for j in 向量组_排序[i * 每段长度:(i + 1) * 每段长度]])
            for j in range(i * 每段长度, (i + 1) * 每段长度):
                向量组_排序[j][针对向量第几维平均化] = 每段总和 / 每段长度
        每段总和 = sum([j[针对向量第几维平均化] for j in 向量组_排序[(总段数 - 1) * 每段长度:]])
        for j in range((总段数 - 1) * 每段长度, len(向量组)):
            向量组_排序[j][针对向量第几维平均化] = 每段总和 / 最后一段长度
        return 向量组_排序


def 运行_基于LDA(输出文件目录, topN=20, 输出评分矩阵=False, **kwargs):
    输出文件目录 = os.path.expanduser(输出文件目录)
    文档_主题_次数矩阵地址 = 输出文件目录 + '4-文档_主题_次数矩阵.txt'
    狄利克雷_alpha = 0.5
    初始总LM值 = float(10 ** 200)

    c测试论文 = 测试论文(引用论文_文本_选择专家_年份表d地址=输出文件目录 + 'e+稿件编号_文本_选择专家_年份表d.pkl',
                 词号_词次数_词表地址=输出文件目录 + '3-词号_词次数_词表.txt',
                 主题_词分布地址=输出文件目录 + '3-主题_词分布.txt',
                 alpha=狄利克雷_alpha,
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 选择特定稿件编号=[],
                 选择稿件数量=-1)

    c专家 = 专家(作者号_论文号广义表地址=输出文件目录 + 'a+作者号_论文号广义表.txt',
             专家_主题_时间8出现次数张量d地址=输出文件目录 + 'f+专家_主题_时间8出现次数张量d.pkl',
             作者_主题分布地址=输出文件目录 + '3-作者_主题分布.txt',
             专家_主题_时间8分布张量d地址=输出文件目录 + 'f+专家_主题_时间8分布张量d.pkl',
             文档编号_文档名表地址=输出文件目录 + '3-文档编号_文档名表.txt',
             作者号_词_词数广义表地址=输出文件目录 + '4-作者号_词_词数广义表.txt',
             初始总LM值=初始总LM值)

    c专家论文 = 专家论文(文档_主题分布地址=输出文件目录 + '4-文档_主题分布.txt',
                 论文号_作者号广义表地址=输出文件目录 + 'a+论文号_作者号广义表.txt',
                 文档号_词_词数广义表地址=输出文件目录 + '4-文档号_词_词数广义表.txt',
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 初始总LM值=初始总LM值)

    速度参数_专家论文 = 0.05 if '速度参数_专家论文' not in kwargs else kwargs['速度参数_专家论文']
    速度参数_专家 = 0.05 if '速度参数_专家' not in kwargs else kwargs['速度参数_专家']
    迭代累加方式 = lambda x: 迭代周围得分方式.衰减求和_分段_舍弃最后归一化(x, 衰减系数=0.25 if '衰减系数' not in kwargs else kwargs['衰减系数'], 每段个数=1)
    展示指标 = [0, 0, 0, 1, 1, 1, 0, 1, 1, 1]  # P_N, MAP, NDCG, 正, Fbeta, 反Fbeta, MAP用N, 无序NDCG, Bpref用N

    print('------我的算法')
    c评估 = 评估(c测试论文, c专家, c专家论文,
             专家论文累计的半衰期=3,  # 半衰期可能无用了
             测试论文时间统一置为=0,
             领域相似度策略=领域相似度计算方法.主题分布NDCG距离,
             topN排序值=80 if 'topN排序值' not in kwargs else kwargs['topN排序值'],  # 用于限制LM值连乘的个数, 小于等于0表示不使用语言模型
             # 迭代过程输出文件夹=输出文件目录+'迭代统计结果',
             测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l地址=输出文件目录 + 'g+测试论文_专家覆盖结果_论文覆盖结果_答案专家广义表l.pkl',
             保存T读取F=True,
             )
    最优结果 = c评估.多次迭代并评估(
        迭代次数=5,
        topN=topN,
        速度参数_专家论文=速度参数_专家论文, 速度参数_专家=速度参数_专家,
        迭代累加方式=迭代累加方式,
        展示指标=展示指标,
        平均化处理对象=2,  # 0代表不处理，1代表专家对专家处理，2代表对专家论文处理，3代表专家和专家论文都处理
        迭代后平均化处理=False,
        # 最优预测结果保存地址=输出文件目录 + 'g+WSIM预测结果.txt',
        评分矩阵输出地址=(输出文件目录 + f'g+评分矩阵/g+LDA-NDCG+I-LM.txt') if 输出评分矩阵 else '',
        最优评分矩阵输出地址=(输出文件目录 + f'g+评分矩阵/g+WSIM.txt') if 输出评分矩阵 else '',
        评分矩阵选择专家覆盖结果的第几个=3
    )
    return 最优结果


def 运行_LDA算法(输出文件目录, topN=20, LDA相似度='COS', 输出评分矩阵=False, **kwargs):
    输出文件目录 = os.path.expanduser(输出文件目录)
    文档_主题_次数矩阵地址 = 输出文件目录 + '4-文档_主题_次数矩阵.txt'
    狄利克雷_alpha = 0.5
    初始总LM值 = float(10 ** 200)

    c测试论文 = 测试论文(引用论文_文本_选择专家_年份表d地址=输出文件目录 + 'e+稿件编号_文本_选择专家_年份表d.pkl',
                 词号_词次数_词表地址=输出文件目录 + '3-词号_词次数_词表.txt',
                 主题_词分布地址=输出文件目录 + '3-主题_词分布.txt',
                 alpha=狄利克雷_alpha,
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 选择特定稿件编号=[],
                 选择稿件数量=-1)

    c专家 = 专家(作者号_论文号广义表地址=输出文件目录 + 'a+作者号_论文号广义表.txt',
             专家_主题_时间8出现次数张量d地址=输出文件目录 + 'f+专家_主题_时间8出现次数张量d.pkl',
             作者_主题分布地址=输出文件目录 + '3-作者_主题分布.txt',
             专家_主题_时间8分布张量d地址=输出文件目录 + 'f+专家_主题_时间8分布张量d.pkl',
             文档编号_文档名表地址=输出文件目录 + '3-文档编号_文档名表.txt',
             作者号_词_词数广义表地址=输出文件目录 + '4-作者号_词_词数广义表.txt',
             初始总LM值=初始总LM值)

    c专家论文 = 专家论文(文档_主题分布地址=输出文件目录 + '4-文档_主题分布.txt',
                 论文号_作者号广义表地址=输出文件目录 + 'a+论文号_作者号广义表.txt',
                 文档号_词_词数广义表地址=输出文件目录 + '4-文档号_词_词数广义表.txt',
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 初始总LM值=初始总LM值)

    速度参数_专家论文 = 0.05
    速度参数_专家 = 0.05
    # 迭代累加方式=lambda x:迭代周围得分方式.衰减求和(x,衰减系数=0.25)
    迭代累加方式 = lambda x: 迭代周围得分方式.衰减求和_分段_舍弃最后归一化(x, 衰减系数=0.25, 每段个数=1)
    展示指标 = [0, 0, 0, 1, 1, 1, 0, 1, 1, 1]  # P_N, MAP, NDCG, 正, Fbeta, 反Fbeta, MAP用N, 无序NDCG, Bpref用N

    相似度 = {
        'COS': 领域相似度计算方法.主题分布余弦距离,
        'NDCG': 领域相似度计算方法.主题分布NDCG距离,
        'ED': 领域相似度计算方法.主题分布欧式距离,
        'JS': 领域相似度计算方法.主题分布JS距离,
    }

    print(f'------LDA-{LDA相似度}算法')
    c评估 = 评估(c测试论文, c专家, c专家论文,
             专家论文累计的半衰期=3,  # 半衰期可能无用了
             测试论文时间统一置为=0,
             领域相似度策略=相似度[LDA相似度],
             topN排序值=0,  # 用于限制LM值连乘的个数, 小于等于0表示不使用语言模型
             # 迭代过程输出文件夹=输出文件目录+'迭代统计结果',
             )
    c评估.多次迭代并评估(迭代次数=0, topN=topN,
                速度参数_专家论文=速度参数_专家论文, 速度参数_专家=速度参数_专家,
                迭代累加方式=迭代累加方式,
                展示指标=展示指标,  # P_N, MAP, NDCG, 正确率, 召回率, Fbeta, 反Fbeta
                评分矩阵输出地址=(输出文件目录 + f'g+评分矩阵/g+LDA-{LDA相似度}.txt') if 输出评分矩阵 else '',
                评分矩阵选择专家覆盖结果的第几个=3
                )


def 运行_LM算法(输出文件目录, topN=20, LM改进=False, 输出评分矩阵=False, **kwargs):
    输出文件目录 = os.path.expanduser(输出文件目录)
    文档_主题_次数矩阵地址 = 输出文件目录 + '4-文档_主题_次数矩阵.txt'
    狄利克雷_alpha = 0.5
    初始总LM值 = float(10 ** 200)

    c测试论文 = 测试论文(引用论文_文本_选择专家_年份表d地址=输出文件目录 + 'e+稿件编号_文本_选择专家_年份表d.pkl',
                 词号_词次数_词表地址=输出文件目录 + '3-词号_词次数_词表.txt',
                 主题_词分布地址=输出文件目录 + '3-主题_词分布.txt',
                 alpha=狄利克雷_alpha,
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,  # 帮助计算 词-主题分布   2018年04月07日
                 选择特定稿件编号=[],  # 优先考虑这个选项
                 选择稿件数量=-1)

    c专家 = 专家(作者号_论文号广义表地址=输出文件目录 + 'a+作者号_论文号广义表.txt',
             专家_主题_时间8出现次数张量d地址=输出文件目录 + 'f+专家_主题_时间8出现次数张量d.pkl',
             作者_主题分布地址=输出文件目录 + '3-作者_主题分布.txt',
             专家_主题_时间8分布张量d地址=输出文件目录 + 'f+专家_主题_时间8分布张量d.pkl',
             文档编号_文档名表地址=输出文件目录 + '3-文档编号_文档名表.txt',
             作者号_词_词数广义表地址=输出文件目录 + '4-作者号_词_词数广义表.txt',
             初始总LM值=初始总LM值)

    c专家论文 = 专家论文(文档_主题分布地址=输出文件目录 + '4-文档_主题分布.txt',
                 论文号_作者号广义表地址=输出文件目录 + 'a+论文号_作者号广义表.txt',
                 文档号_词_词数广义表地址=输出文件目录 + '4-文档号_词_词数广义表.txt',
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 初始总LM值=初始总LM值)

    速度参数_专家论文 = 0.05
    速度参数_专家 = 0.05
    # 迭代累加方式=lambda x:迭代周围得分方式.衰减求和(x,衰减系数=0.25)
    迭代累加方式 = lambda x: 迭代周围得分方式.衰减求和_分段_舍弃最后归一化(x, 衰减系数=0.25, 每段个数=1)
    展示指标 = [0, 0, 0, 1, 1, 1, 0, 1, 1, 1]  # P_N, MAP, NDCG, 正, Fbeta, 反Fbeta, MAP用N, 无序NDCG, Bpref用N

    if LM改进:
        LM_描述 = 'I-LM'
        去重复 = True
        topN排序值 = 80
    else:
        LM_描述 = 'LM'
        去重复 = False
        topN排序值 = 0

    c专家.改变LM计算时是否去除重复词(去重复=去重复)  # 标准的LM中不去重复,保留所有的词连乘
    c专家论文.改变LM计算时是否去除重复词(去重复=去重复)

    print(f'------{LM_描述}算法')
    c评估 = 评估(c测试论文, c专家, c专家论文,
             专家论文累计的半衰期=3,
             测试论文时间统一置为=0,
             领域相似度策略=领域相似度计算方法.LM值,
             topN排序值=topN排序值,  # 用于限制LM值连乘的个数, 小于等于0表示不使用语言模型
             # 迭代过程输出文件夹=输出文件目录+'迭代统计结果',
             )
    c评估.多次迭代并评估(迭代次数=0, topN=topN,
                速度参数_专家论文=速度参数_专家论文, 速度参数_专家=速度参数_专家,
                迭代累加方式=迭代累加方式,
                展示指标=展示指标,  # P_N, MAP, NDCG, 正确率, 召回率, Fbeta, 反Fbeta
                评分矩阵输出地址=(输出文件目录 + f'g+评分矩阵/g+{LM_描述}.txt') if 输出评分矩阵 else '',
                评分矩阵选择专家覆盖结果的第几个=3
                )


def 运行_LDA和LM算法(输出文件目录, topN=20, 输出评分矩阵=False, **kwargs):
    输出文件目录 = os.path.expanduser(输出文件目录)
    文档_主题_次数矩阵地址 = 输出文件目录 + '4-文档_主题_次数矩阵.txt'
    狄利克雷_alpha = 0.5
    初始总LM值 = float(10 ** 200)

    c测试论文 = 测试论文(引用论文_文本_选择专家_年份表d地址=输出文件目录 + 'e+稿件编号_文本_选择专家_年份表d.pkl',
                 词号_词次数_词表地址=输出文件目录 + '3-词号_词次数_词表.txt',
                 主题_词分布地址=输出文件目录 + '3-主题_词分布.txt',
                 alpha=狄利克雷_alpha,
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 选择特定稿件编号=[],  # 优先考虑这个选项
                 选择稿件数量=-1)

    c专家 = 专家(作者号_论文号广义表地址=输出文件目录 + 'a+作者号_论文号广义表.txt',
             专家_主题_时间8出现次数张量d地址=输出文件目录 + 'f+专家_主题_时间8出现次数张量d.pkl',
             作者_主题分布地址=输出文件目录 + '3-作者_主题分布.txt',
             专家_主题_时间8分布张量d地址=输出文件目录 + 'f+专家_主题_时间8分布张量d.pkl',
             文档编号_文档名表地址=输出文件目录 + '3-文档编号_文档名表.txt',
             作者号_词_词数广义表地址=输出文件目录 + '4-作者号_词_词数广义表.txt',
             初始总LM值=初始总LM值)

    c专家论文 = 专家论文(文档_主题分布地址=输出文件目录 + '4-文档_主题分布.txt',
                 论文号_作者号广义表地址=输出文件目录 + 'a+论文号_作者号广义表.txt',
                 文档号_词_词数广义表地址=输出文件目录 + '4-文档号_词_词数广义表.txt',
                 文档_主题_次数矩阵地址=文档_主题_次数矩阵地址,
                 初始总LM值=初始总LM值)

    速度参数_专家论文 = 0.05
    速度参数_专家 = 0.05
    # 迭代累加方式=lambda x:迭代周围得分方式.衰减求和(x,衰减系数=0.25)
    迭代累加方式 = lambda x: 迭代周围得分方式.衰减求和_分段_舍弃最后归一化(x, 衰减系数=0.25, 每段个数=1)
    展示指标 = [0, 0, 0, 1, 1, 1, 0, 1, 1, 1]  # P_N, MAP, NDCG, 正, Fbeta, 反Fbeta, MAP用N, 无序NDCG, Bpref用N

    c专家.改变LM计算时是否去除重复词(去重复=False)  # 标准的LM中不去重复,保留所有的词连乘
    c专家论文.改变LM计算时是否去除重复词(去重复=False)

    print('------LDA+LM算法')
    c评估 = 评估(c测试论文, c专家, c专家论文,
             专家论文累计的半衰期=3,  # 半衰期可能无用了
             测试论文时间统一置为=0,
             领域相似度策略=领域相似度计算方法.主题分布余弦距离,
             topN排序值=100000,  # 用于限制LM值连乘的个数, 小于等于0表示不使用语言模型. 不想限制时必须大于稿件数量
             # 迭代过程输出文件夹=输出文件目录+'迭代统计结果',
             )
    c评估.多次迭代并评估(迭代次数=0, topN=topN,
                速度参数_专家论文=速度参数_专家论文, 速度参数_专家=速度参数_专家,
                迭代累加方式=迭代累加方式,
                展示指标=展示指标,  # P_N, MAP, NDCG, 正确率, 召回率, Fbeta, 反Fbeta
                评分矩阵输出地址=(输出文件目录 + f'g+评分矩阵/g+LDA+LM.txt') if 输出评分矩阵 else '',
                评分矩阵选择专家覆盖结果的第几个=3
                )


def RandomizedSearch():
    输出文件目录 = '~/code/data/1-RAP/输出文件目录-16/'
    topN = 20
    params = {
        '速度参数_专家论文': [0.05, 0.1, 0.15, 0.2],
        '速度参数_专家': [0.05, 0.1, 0.15, 0.2],
        '衰减系数': [0.1, 0.25, 0.4, 0.55],
        'topN排序值': [50, 80, 110, 140],
    }
    print('-' * 20 + 'RandomizedSearch')
    pprint(params)

    have_param_S = {tuple()}
    p_L = []
    p_D = {}
    最优结果 = 0
    最优参数 = p_D
    最优参数是第几次随机 = 0
    for i in range(25):
        while tuple(p_L) in have_param_S:
            p_L = []
            p_D = {}
            for k, v in params.items():
                p = random.choice(v)
                p_L.append(p)
                p_D[k] = p
        have_param_S.add(tuple(p_L))
        print('-' * 20 + f'寻找参数({i + 1}次): {p_D}')
        结果 = 运行_基于LDA(输出文件目录, topN, **p_D)
        if 结果 > 最优结果:
            最优结果 = 结果
            最优参数 = p_D
            最优参数是第几次随机 = i + 1
        print()
        print(f'目前最优参数(第{最优参数是第几次随机}次,{最优结果}): {最优参数}')


def main():
    开始时间 = time.time()
    print(datetime.datetime.now())

    kwargs = {  # 不是所有参数都对运行函数起作用, 需检查运行函数传入参数
        '输出文件目录': '输出文件目录-10/',  # 10: First dataset, 14: Second dataset, 16: Validation dataset
        'topN': 20,
        'LM改进': False,
        'LDA相似度': 'COS',  # COS, NDCG, ED, JS
        '输出评分矩阵': False,
        '速度参数_专家论文': 0.05,
        '速度参数_专家': 0.05,
        '衰减系数': 0.25,
        'topN排序值': 80,
    }
    print(f'初始参数: (不是所有参数都对运行函数起作用, 需检查运行函数传入参数)\n', kwargs)
    参数分析 = False

    # 参数分析
    if 参数分析:
        分析内容 = [
            ('速度参数_专家论文', [0.01, 0.05, 0.1, 0.15, 0.2, 0.25]),
            ('速度参数_专家', [0.01, 0.05, 0.1, 0.15, 0.2, 0.25]),
            ('衰减系数', [0.05, 0.15, 0.25, 0.35, 0.45, 0.55]),
            ('topN排序值', [20, 50, 80, 110, 140, 170]),
        ]
        for 描述, 候选 in 分析内容:
            默认 = kwargs[描述]
            for i in 候选:
                if 默认 == i:
                    continue
                kwargs[描述] = i
                print(f'参数:', kwargs)
                运行_基于LDA(**kwargs)
            kwargs[描述] = 默认
            print()

    运行_基于LDA(**kwargs)  # 论文中算法, WSIM / LDA-NDCG+I-LM
    for i in [True, False]:
        kwargs['LM改进'] = i
        运行_LM算法(**kwargs)  # LM / I-LM
    for i in ['COS', 'NDCG', 'ED', 'JS']:
        kwargs['LDA相似度'] = i
        运行_LDA算法(**kwargs)  # LDA / LDA-NDCG
    运行_LDA和LM算法(**kwargs)  # LDA-LM

    print('共耗时:%f分钟' % ((time.time() - 开始时间) / 60))


if __name__ == '__main__':
    # RandomizedSearch()
    main()
